#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤æ˜“ç³»ç»Ÿæµ‹è¯•å·¥å…·
ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æµ‹è¯•åŠŸèƒ½ï¼šå‡†å¤‡æ£€æŸ¥ã€æŸ¥çœ‹æŒä»“ã€æ¸…ç†æŒä»“ã€æ‰§è¡Œæµ‹è¯•ä¸‹å•ç­‰
"""

import argparse
import json
import os
import sys
import time
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    import redis
    from libs.common.config import settings
    from libs.common.time import now_ms
    from libs.common.timeframe import timeframe_ms
    from libs.db.pg import get_conn
    from libs.bybit.market_rest import BybitMarketRestClient
    from libs.bybit.trade_rest_v5 import TradeRestV5Client
    from libs.bybit.intervals import bybit_interval_for_system_timeframe
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("\nğŸ’¡ æç¤ºï¼šåœ¨ Docker å®¹å™¨ä¸­è¿è¡Œï¼š")
    print("   docker compose exec execution python -m scripts.trading_test_tool --help")
    sys.exit(1)

# é¢œè‰²å®šä¹‰
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    NC = '\033[0m'

def print_info(msg: str):
    print(f"{Colors.BLUE}[INFO]{Colors.NC} {msg}")

def print_success(msg: str):
    print(f"{Colors.GREEN}[SUCCESS]{Colors.NC} {msg}")

def print_error(msg: str):
    print(f"{Colors.RED}[ERROR]{Colors.NC} {msg}")

def print_warning(msg: str):
    print(f"{Colors.YELLOW}[WARNING]{Colors.NC} {msg}")

# ==================== å‡†å¤‡æ£€æŸ¥åŠŸèƒ½ ====================

def check_config() -> bool:
    """æ£€æŸ¥é…ç½®"""
    print_info("æ£€æŸ¥é…ç½®...")
    
    if str(settings.execution_mode).upper() != "LIVE":
        print_error(f"EXECUTION_MODE ä¸æ˜¯ LIVE")
        print(f"   å½“å‰å€¼: {settings.execution_mode}")
        print("   è¯·è®¾ç½®: EXECUTION_MODE=LIVE")
        return False
    print_success("EXECUTION_MODE=LIVE")
    
    if not settings.bybit_api_key or not settings.bybit_api_secret:
        print_error("Bybit API Key/Secret æœªé…ç½®")
        print("   è¯·è®¾ç½®: BYBIT_API_KEY å’Œ BYBIT_API_SECRET")
        return False
    print_success("Bybit API Key/Secret å·²é…ç½®")
    
    return True

def check_service_status() -> bool:
    """æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
    print_info("æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    
    try:
        import requests
        health_url = "http://localhost:8003/health"
        response = requests.get(health_url, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            if data.get("execution_mode") == "LIVE":
                print_success("æ‰§è¡ŒæœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡")
                return True
            else:
                print_warning(f"æ‰§è¡ŒæœåŠ¡è¿è¡Œä¸­ï¼Œä½†æ¨¡å¼æ˜¯ {data.get('execution_mode')}")
                return True
        else:
            print_warning("æ— æ³•è®¿é—®å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œä½†æœåŠ¡å¯èƒ½åœ¨è¿è¡Œ")
            return True
    except ImportError:
        print_warning("æœªå®‰è£… requests åº“ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥")
        return True
    except Exception as e:
        print_warning(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        print_info("è¯·æ‰‹åŠ¨æ£€æŸ¥æœåŠ¡çŠ¶æ€: docker compose ps execution")
        return True

def check_all_services_health() -> bool:
    """æ£€æŸ¥æ‰€æœ‰æœåŠ¡çš„å¥åº·çŠ¶æ€"""
    DEFAULT_PORTS = {
        "api": 8000,
        "marketdata": 8001,
        "strategy": 8002,
        "execution": 8003,
        "notifier": 8004,
    }
    
    print_info("æ£€æŸ¥æ‰€æœ‰æœåŠ¡å¥åº·çŠ¶æ€...")
    ok = True
    
    try:
        import requests
        base_url = "http://localhost"
        
        for name, port in DEFAULT_PORTS.items():
            url = f"{base_url}:{port}/health"
            try:
                response = requests.get(url, timeout=3)
                if response.status_code == 200:
                    data = response.json()
                    print_success(f"{name:12s} {url} -> OK")
                else:
                    ok = False
                    print_error(f"{name:12s} {url} -> {response.status_code}")
            except Exception as e:
                ok = False
                print_error(f"{name:12s} {url} -> {str(e)}")
        
        return ok
    except ImportError:
        print_warning("æœªå®‰è£… requests åº“ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥")
        return True
    except Exception as e:
        print_warning(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False

def check_redis_streams() -> bool:
    """æ£€æŸ¥ Redis Streams çŠ¶æ€"""
    print_info("æ£€æŸ¥ Redis Streams çŠ¶æ€...")
    
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=True)
        r.ping()
        print_success("Redis è¿æ¥æ­£å¸¸")
        
        streams = [
            "stream:dlq",
            "stream:bar_close",
            "stream:signal",
            "stream:trade_plan",
            "stream:execution_report",
            "stream:risk_event",
        ]
        
        for stream in streams:
            try:
                info = r.xinfo_stream(stream)
                groups = r.xinfo_groups(stream)
                length = info.get("length", 0)
                last_id = info.get("last-generated-id", "0-0")
                print_info(f"  {stream}: length={length}, last_id={last_id}, groups={len(groups)}")
            except Exception as e:
                print_warning(f"  {stream}: {str(e)}")
        
        return True
    except Exception as e:
        print_error(f"Redis æ£€æŸ¥å¤±è´¥: {e}")
        return False

def show_config():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    print_info("å½“å‰é£é™©é…ç½®...")
    print(f"   RISK_PCT: {settings.risk_pct}")
    print(f"   MAX_OPEN_POSITIONS: {settings.max_open_positions}")
    print(f"   ACCOUNT_KILL_SWITCH_ENABLED: {settings.account_kill_switch_enabled}")
    print(f"   RISK_CIRCUIT_ENABLED: {settings.risk_circuit_enabled}")
    print(f"   DAILY_LOSS_LIMIT_PCT: {getattr(settings, 'daily_loss_limit_pct', 'æœªè®¾ç½®')}")

def cmd_prepare():
    """å‡†å¤‡æ£€æŸ¥å‘½ä»¤"""
    print("=" * 60)
    print("  å®ç›˜ä¸‹å•æµ‹è¯•å‡†å¤‡")
    print("=" * 60)
    print()
    
    if not check_config():
        sys.exit(1)
    
    print()
    check_all_services_health()
    print()
    check_redis_streams()
    print()
    show_config()
    print()
    
    print_success("å‡†å¤‡å®Œæˆï¼")
    print()
    print_warning("âš ï¸  é‡è¦æé†’ï¼š")
    print("   1. ç¡®ä¿ RISK_PCT â‰¤ 0.001ï¼ˆ0.1%ï¼‰")
    print("   2. å®æ—¶ç›‘æ§æ‰§è¡ŒæœåŠ¡æ—¥å¿—")
    print("   3. åœ¨ Bybit äº¤æ˜“æ‰€éªŒè¯è®¢å•")
    print("   4. å‡†å¤‡å¥½ç´§æ€¥åœæ­¢æ–¹æ¡ˆ")

# ==================== æŸ¥çœ‹æŒä»“åŠŸèƒ½ ====================

def show_open_positions(detailed: bool = False) -> List[Dict[str, Any]]:
    """æ˜¾ç¤ºæ‰€æœ‰ OPEN æŒä»“"""
    db_url = settings.database_url
    
    with get_conn(db_url) as conn:
        with conn.cursor() as cur:
            if detailed:
                cur.execute("""
                    SELECT 
                        position_id,
                        idempotency_key,
                        symbol,
                        timeframe,
                        side,
                        qty_total,
                        entry_price,
                        primary_sl_price,
                        status,
                        created_at,
                        CASE 
                            WHEN position_id LIKE 'paper-%' THEN 'PAPERæ¨¡å¼'
                            WHEN idempotency_key LIKE 'paper-%' THEN 'PAPERæ¨¡å¼'
                            WHEN idempotency_key LIKE 'idem-%' THEN 'æµ‹è¯•æ³¨å…¥'
                            ELSE 'æœªçŸ¥æ¥æº'
                        END as source_type
                    FROM positions 
                    WHERE status = 'OPEN'
                    ORDER BY created_at DESC;
                """)
            else:
                cur.execute("""
                    SELECT 
                        position_id,
                        idempotency_key,
                        symbol,
                        side,
                        qty_total,
                        status,
                        created_at
                    FROM positions 
                    WHERE status = 'OPEN'
                    ORDER BY created_at DESC;
                """)
            
            cols = [desc[0] for desc in cur.description]
            rows = cur.fetchall()
            
            if not rows:
                print("æ²¡æœ‰æ‰¾åˆ° OPEN æŒä»“")
                return []
            
            # æ‰“å°è¡¨å¤´
            header = " | ".join(f"{col:30}" for col in cols)
            print(header)
            print("-" * len(header))
            
            # æ‰“å°æ•°æ®
            positions = []
            for row in rows:
                pos_dict = dict(zip(cols, row))
                positions.append(pos_dict)
                row_str = " | ".join(f"{str(v) if v is not None else 'NULL':30}" for v in row)
                print(row_str)
            
            # ç»Ÿè®¡ä¿¡æ¯
            print()
            print_info("æŒä»“æ•°é‡ç»Ÿè®¡ï¼š")
            cur.execute("""
                SELECT 
                    COUNT(*) as total_open,
                    COUNT(CASE WHEN position_id LIKE 'paper-%' OR idempotency_key LIKE 'paper-%' THEN 1 END) as paper_count,
                    COUNT(CASE WHEN idempotency_key LIKE 'idem-%' THEN 1 END) as test_count
                FROM positions 
                WHERE status = 'OPEN';
            """)
            
            stats = dict(zip(['total_open', 'paper_count', 'test_count'], cur.fetchone()))
            print(f"  æ€» OPEN æŒä»“æ•°: {stats['total_open']}")
            print(f"  PAPER æ¨¡å¼æŒä»“: {stats['paper_count']}")
            print(f"  æµ‹è¯•æ³¨å…¥æŒä»“: {stats['test_count']}")
            
            return positions

def cmd_positions(args):
    """æŸ¥çœ‹æŒä»“å‘½ä»¤"""
    print("=" * 60)
    print("  æŸ¥çœ‹æ‰€æœ‰ OPEN æŒä»“")
    print("=" * 60)
    print()
    
    show_open_positions(detailed=args.detailed)

# ==================== æ¸…ç†æŒä»“åŠŸèƒ½ ====================

def close_position(position_id: str) -> bool:
    """å…³é—­æŒ‡å®šæŒä»“"""
    db_url = settings.database_url
    
    with get_conn(db_url) as conn:
        with conn.cursor() as cur:
            # å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨
            cur.execute("""
                SELECT position_id, symbol, side, qty_total, status 
                FROM positions 
                WHERE (position_id = %s OR idempotency_key = %s OR position_id LIKE %s)
                AND status = 'OPEN';
            """, (position_id, position_id, f"{position_id}%"))
            
            row = cur.fetchone()
            if not row:
                print_error(f"æœªæ‰¾åˆ°åŒ¹é…çš„ OPEN æŒä»“: {position_id}")
                return False
            
            print_success(f"æ‰¾åˆ°æŒä»“: {dict(zip(['position_id', 'symbol', 'side', 'qty_total', 'status'], row))}")
            
            # å…³é—­æŒä»“
            cur.execute("""
                UPDATE positions 
                SET 
                    status = 'CLOSED',
                    updated_at = now(),
                    closed_at_ms = extract(epoch from now())::bigint * 1000,
                    exit_reason = 'MANUAL_FORCE_CLOSE'
                WHERE (position_id = %s OR idempotency_key = %s OR position_id LIKE %s)
                AND status = 'OPEN'
                RETURNING position_id;
            """, (position_id, position_id, f"{position_id}%"))
            
            result = cur.fetchone()
            conn.commit()
            
            if result:
                print_success(f"å·²å…³é—­æŒä»“: {result[0]}")
                return True
            else:
                print_error("å…³é—­å¤±è´¥")
                return False

def close_all_positions(confirm: bool = False) -> int:
    """å…³é—­æ‰€æœ‰ OPEN æŒä»“"""
    db_url = settings.database_url
    
    with get_conn(db_url) as conn:
        with conn.cursor() as cur:
            # å…ˆæŸ¥è¯¢æ‰€æœ‰ OPEN æŒä»“
            cur.execute("""
                SELECT 
                    position_id,
                    idempotency_key,
                    symbol,
                    side,
                    qty_total
                FROM positions 
                WHERE status = 'OPEN'
                ORDER BY created_at DESC;
            """)
            
            positions = cur.fetchall()
            
            if not positions:
                print("æ²¡æœ‰æ‰¾åˆ° OPEN æŒä»“")
                return 0
            
            print_warning(f"æ‰¾åˆ° {len(positions)} ä¸ª OPEN æŒä»“ï¼Œå°†å…¨éƒ¨å…³é—­")
            print()
            
            if not confirm:
                response = input("ç¡®è®¤å…³é—­æ‰€æœ‰ OPEN æŒä»“? (yes/no): ")
                if response.lower() not in ['yes', 'y']:
                    print("å–æ¶ˆæ“ä½œ")
                    return 0
            
            # å…³é—­æ‰€æœ‰
            cur.execute("""
                UPDATE positions 
                SET 
                    status = 'CLOSED',
                    updated_at = now(),
                    closed_at_ms = extract(epoch from now())::bigint * 1000,
                    exit_reason = 'MANUAL_FORCE_CLOSE'
                WHERE status = 'OPEN'
                RETURNING position_id;
            """)
            
            closed = cur.fetchall()
            conn.commit()
            
            print_success(f"å·²å…³é—­ {len(closed)} ä¸ªæŒä»“")
            for pos in closed:
                print(f"   - {pos[0]}")
            
            return len(closed)

def cmd_clean(args):
    """æ¸…ç†æŒä»“å‘½ä»¤"""
    print("=" * 60)
    print("  æ¸…ç†æŒä»“")
    print("=" * 60)
    print()
    
    if args.all:
        close_all_positions(confirm=args.yes)
    elif args.position_id:
        if not args.yes:
            show_open_positions()
            print()
            response = input(f"ç¡®è®¤å…³é—­æŒä»“ {args.position_id}? (yes/no): ")
            if response.lower() not in ['yes', 'y']:
                print("å–æ¶ˆæ“ä½œ")
                return
        
        close_position(args.position_id)
    else:
        print_error("è¯·æŒ‡å®š --all æˆ– <position_id>")
        return
    
    # éªŒè¯ç»“æœ
    print()
    print_info("éªŒè¯ç»“æœ...")
    with get_conn(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT COUNT(*) FROM positions WHERE status='OPEN';")
            remaining = cur.fetchone()[0]
            
            if remaining == 0:
                print_success("æ‰€æœ‰ OPEN æŒä»“å·²æ¸…ç†")
            else:
                print_warning(f"ä»æœ‰ {remaining} ä¸ª OPEN æŒä»“")

# ==================== è·å–å¸‚åœºä»·æ ¼åŠŸèƒ½ ====================

def get_current_market_price(symbol: str) -> Optional[float]:
    """è·å–å½“å‰å¸‚åœºä»·æ ¼ï¼ˆä½¿ç”¨æœ€æ–° K çº¿æ”¶ç›˜ä»·ï¼‰"""
    try:
        client = BybitMarketRestClient(base_url=settings.bybit_rest_base_url)
        klines = client.get_kline(
            symbol=symbol.upper(),
            interval="1",  # 1 åˆ†é’Ÿ K çº¿
            category=settings.bybit_category,
            limit=1,
        )
        if klines and len(klines) > 0:
            return float(klines[0]["close"])
        return None
    except Exception as e:
        print_error(f"è·å–å¸‚åœºä»·æ ¼å¤±è´¥: {e}")
        return None

def calculate_entry_and_sl_prices(
    symbol: str,
    side: str,
    current_price: float,
    sl_distance_pct: float = 0.02,  # é»˜è®¤æ­¢æŸè·ç¦» 2%
) -> Tuple[float, float]:
    """æ ¹æ®å½“å‰ä»·æ ¼å’Œæ–¹å‘è®¡ç®—å…¥åœºä»·å’Œæ­¢æŸä»·"""
    side_upper = side.upper()
    
    if side_upper == "BUY":
        # BUY: å…¥åœºä»·ä½¿ç”¨å½“å‰ä»·æ ¼ï¼Œæ­¢æŸä»·åœ¨å½“å‰ä»·æ ¼ä¸‹æ–¹
        entry_price = current_price
        sl_price = current_price * (1 - sl_distance_pct)
    elif side_upper == "SELL":
        # SELL: å…¥åœºä»·ä½¿ç”¨å½“å‰ä»·æ ¼ï¼Œæ­¢æŸä»·åœ¨å½“å‰ä»·æ ¼ä¸Šæ–¹
        entry_price = current_price
        sl_price = current_price * (1 + sl_distance_pct)
    else:
        raise ValueError(f"æ— æ•ˆçš„ side: {side}")
    
    return entry_price, sl_price

# ==================== æ‰§è¡Œæµ‹è¯•ä¸‹å•åŠŸèƒ½ ====================

def build_trade_plan(
    symbol: str,
    timeframe: str,
    side: str,
    entry_price: float,
    sl_price: float,
    env: str = "prod",
) -> Dict[str, Any]:
    """æ„å»º trade_plan äº‹ä»¶"""
    now = now_ms()
    plan_id = f"live-test-{uuid.uuid4().hex[:12]}"
    idem = f"idem-{uuid.uuid4().hex}"
    
    event = {
        "event_id": f"evt-{uuid.uuid4().hex}",
        "ts_ms": now,
        "env": env,
        "service": "strategy-service",
        "schema_version": 1,
        "payload": {
            "plan_id": plan_id,
            "idempotency_key": idem,
            "symbol": symbol,
            "timeframe": timeframe,
            "side": side,
            "entry_price": entry_price,
            "primary_sl_price": sl_price,
            "tp_rules": {
                "tp1": {"r": 1.0, "pct": 0.4},
                "tp2": {"r": 2.0, "pct": 0.4},
                "tp3_trail": {"pct": 0.2, "mode": "ATR"},
                "reduce_only": True,
            },
            "secondary_sl_rule": {"type": "NEXT_BAR_NOT_SHORTEN_EXIT"},
            "traceability": {"setup_id": "live-test-setup", "trigger_id": "live-test-trigger"},
            "ext": {"live_test": True, "manual_inject": True},
        },
    }
    return event

def publish_event(
    r: redis.Redis, stream: str, event: Dict[str, Any], event_type: str = "TRADE_PLAN"
) -> str:
    """å‘å¸ƒäº‹ä»¶åˆ° Redis Streams"""
    payload: Dict[str, Any] = {"json": json.dumps(event, ensure_ascii=False)}
    if event_type:
        payload["type"] = event_type
    return r.xadd(stream, payload)

def check_execution_result(
    r: redis.Redis, plan_id: str, idempotency_key: str, wait_seconds: int = 30
) -> None:
    """æ£€æŸ¥æ‰§è¡Œç»“æœ"""
    print(f"\nâ³ ç­‰å¾… {wait_seconds} ç§’è®©æ‰§è¡ŒæœåŠ¡å¤„ç†...")
    time.sleep(wait_seconds)
    
    print("\n" + "=" * 60)
    print("  æ£€æŸ¥æ‰§è¡Œç»“æœ")
    print("=" * 60)
    
    # æ£€æŸ¥ execution_report
    print("\nğŸ“Š æ‰§è¡ŒæŠ¥å‘Š (stream:execution_report):")
    reports = r.xrevrange("stream:execution_report", max="+", min="-", count=50)
    related_reports = []
    for msg_id, fields in reports:
        # å…¼å®¹ä¸¤ç§å­—æ®µæ ¼å¼ï¼šjsonï¼ˆæ—§æ ¼å¼ï¼‰å’Œ dataï¼ˆæ–°æ ¼å¼ï¼‰
        raw_data = fields.get("json") or fields.get("data")
        if raw_data:
            try:
                evt = json.loads(raw_data)
                payload = evt.get("payload", {})
                # æ£€æŸ¥ plan_id æˆ– idempotency_keyï¼ˆå¯èƒ½åœ¨ payload æˆ– ext ä¸­ï¼‰
                ext = payload.get("ext", {}) or {}
                payload_idem = payload.get("idempotency_key") or ext.get("idempotency_key")
                payload_plan_id = payload.get("plan_id")
                if (
                    payload_plan_id == plan_id
                    or payload_idem == idempotency_key
                ):
                    related_reports.append(evt)
            except Exception:
                pass
    
    if related_reports:
        print(f"   æ‰¾åˆ° {len(related_reports)} ä¸ªç›¸å…³æ‰§è¡ŒæŠ¥å‘Š:")
        for i, rep in enumerate(related_reports[:5], 1):
            payload = rep.get("payload", {})
            status = payload.get("status", "")
            symbol = payload.get("symbol", "")
            print(f"   {i}. çŠ¶æ€: {status}, äº¤æ˜“å¯¹: {symbol}")
            
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯æˆ–åŸå› 
            detail = payload.get("detail", {})
            if isinstance(detail, dict):
                reason = detail.get("reason") or detail.get("error")
                if reason:
                    print(f"      åŸå› : {reason}")
            
            # æ˜¾ç¤º ext ä¸­çš„ä¿¡æ¯
            ext = payload.get("ext", {})
            if isinstance(ext, dict):
                ext_detail = ext.get("detail", {})
                if isinstance(ext_detail, dict):
                    ext_reason = ext_detail.get("reason") or ext_detail.get("error")
                    if ext_reason:
                        print(f"      è¯¦ç»†ä¿¡æ¯: {ext_reason}")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ‰§è¡ŒæŠ¥å‘Š")
    
    # æ£€æŸ¥ risk_event
    print("\nâš ï¸  é£é™©äº‹ä»¶ (stream:risk_event):")
    risk_events = r.xrevrange("stream:risk_event", max="+", min="-", count=50)
    related_risks = []
    for msg_id, fields in risk_events:
        # å…¼å®¹ä¸¤ç§å­—æ®µæ ¼å¼ï¼šjsonï¼ˆæ—§æ ¼å¼ï¼‰å’Œ dataï¼ˆæ–°æ ¼å¼ï¼‰
        raw_data = fields.get("json") or fields.get("data")
        if raw_data:
            try:
                evt = json.loads(raw_data)
                payload = evt.get("payload", {})
                detail = payload.get("detail", {}) if isinstance(payload.get("detail"), dict) else {}
                if (
                    detail.get("existing_idempotency_key") == idempotency_key
                    or detail.get("incoming_idempotency_key") == idempotency_key
                    or detail.get("idempotency_key") == idempotency_key
                ):
                    related_risks.append(evt)
            except Exception:
                pass
    
    if related_risks:
        print(f"   æ‰¾åˆ° {len(related_risks)} ä¸ªç›¸å…³é£é™©äº‹ä»¶:")
        for i, risk in enumerate(related_risks[:5], 1):
            payload = risk.get("payload", {})
            print(f"   {i}. {payload.get('type')} - {payload.get('severity')} - {payload.get('symbol')}")
    else:
        print("   âœ… æœªæ‰¾åˆ°ç›¸å…³é£é™©äº‹ä»¶")
    
    print("\n" + "=" * 60)
    print("  éªŒè¯æ­¥éª¤")
    print("=" * 60)
    print("\n1. æŸ¥çœ‹æ‰§è¡ŒæœåŠ¡æ—¥å¿—ï¼š")
    print("   docker compose logs execution | tail -50")
    print("\n2. æŸ¥çœ‹è®¢å•ï¼ˆé€šè¿‡æ­¤å·¥å…·ï¼‰ï¼š")
    print(f"   python -m scripts.trading_test_tool orders --idempotency-key {idempotency_key}")
    print("\n3. æŸ¥çœ‹æŒä»“ï¼ˆé€šè¿‡æ­¤å·¥å…·ï¼‰ï¼š")
    print(f"   python -m scripts.trading_test_tool positions")
    print("\n4. åœ¨ Bybit äº¤æ˜“æ‰€éªŒè¯ï¼š")
    print("   - ç™»å½• Bybit äº¤æ˜“æ‰€")
    print("   - æŸ¥çœ‹'è®¢å•'é¡µé¢ï¼Œç¡®è®¤è®¢å•å·²åˆ›å»º")
    print("   - æŸ¥çœ‹'æŒä»“'é¡µé¢ï¼Œç¡®è®¤æŒä»“æ­£ç¡®")
    print("   - æŸ¥çœ‹'æ¡ä»¶å•'é¡µé¢ï¼Œç¡®è®¤æ­¢æŸ/æ­¢ç›ˆå·²è®¾ç½®")

def cmd_test(args):
    """æ‰§è¡Œæµ‹è¯•ä¸‹å•å‘½ä»¤"""
    # æ£€æŸ¥æ‰§è¡Œæ¨¡å¼
    if str(settings.execution_mode).upper() != "LIVE":
        print_error("å½“å‰æ‰§è¡Œæ¨¡å¼ä¸æ˜¯ LIVE")
        print(f"   å½“å‰æ¨¡å¼: {settings.execution_mode}")
        print("   è¯·è®¾ç½® EXECUTION_MODE=LIVE åå†è¿è¡Œ")
        sys.exit(1)
    
    # æ£€æŸ¥ Bybit API
    if not settings.bybit_api_key or not settings.bybit_api_secret:
        print_error("æœªé…ç½® Bybit API Key/Secret")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® BYBIT_API_KEY å’Œ BYBIT_API_SECRET")
        sys.exit(1)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("=" * 60)
    print("  å®ç›˜ä¸‹å•æµ‹è¯•")
    print("=" * 60)
    print("\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œä¼šçœŸå®ä¸‹å•ï¼")
    print(f"\né…ç½®ä¿¡æ¯ï¼š")
    print(f"  æ‰§è¡Œæ¨¡å¼: {settings.execution_mode}")
    print(f"  é£é™©ç™¾åˆ†æ¯”: {settings.risk_pct} ({settings.risk_pct * 100}%)")
    print(f"  æœ€å¤§æŒä»“æ•°: {settings.max_open_positions}")
    print(f"  è´¦æˆ·ç†”æ–­: {'å¯ç”¨' if settings.account_kill_switch_enabled else 'æœªå¯ç”¨'}")
    
    # è‡ªåŠ¨è·å–æˆ–ä½¿ç”¨æŒ‡å®šçš„ä»·æ ¼
    entry_price = args.entry_price
    sl_price = args.sl_price
    
    if entry_price is None or sl_price is None:
        print_info(f"\næ­£åœ¨è·å– {args.symbol} çš„å½“å‰å¸‚åœºä»·æ ¼...")
        current_price = get_current_market_price(args.symbol)
        
        if current_price is None:
            print_error("æ— æ³•è·å–å¸‚åœºä»·æ ¼ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š --entry-price å’Œ --sl-price")
            sys.exit(1)
        
        print_success(f"å½“å‰å¸‚åœºä»·æ ¼: {current_price}")
        
        # è®¡ç®—å…¥åœºä»·å’Œæ­¢æŸä»·
        entry_price, sl_price = calculate_entry_and_sl_prices(
            symbol=args.symbol,
            side=args.side,
            current_price=current_price,
            sl_distance_pct=args.sl_distance_pct,
        )
        
        print_info(f"è‡ªåŠ¨è®¡ç®—çš„ä»·æ ¼ï¼š")
        print(f"  å…¥åœºä»·æ ¼: {entry_price:.2f}")
        print(f"  æ­¢æŸä»·æ ¼: {sl_price:.2f} (è·ç¦»: {args.sl_distance_pct * 100:.1f}%)")
    
    print(f"\näº¤æ˜“å‚æ•°ï¼š")
    print(f"  äº¤æ˜“å¯¹: {args.symbol}")
    print(f"  æ–¹å‘: {args.side}")
    print(f"  æ—¶é—´æ¡†æ¶: {args.timeframe}")
    print(f"  å…¥åœºä»·æ ¼: {entry_price}")
    print(f"  æ­¢æŸä»·æ ¼: {sl_price}")
    
    # è‡ªåŠ¨è¯Šæ–­ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.auto_diagnose:
        print("\n" + "=" * 60)
        print("  è‡ªåŠ¨è¯Šæ–­ï¼ˆä¸‹å•å‰æ£€æŸ¥ï¼‰")
        print("=" * 60)
        diagnose_order_failure(args.symbol, args.side)
        print()
    
    # ç¡®è®¤
    if not args.confirm:
        print("\n" + "=" * 60)
        response = input("ç¡®è®¤ç»§ç»­ï¼Ÿè¾“å…¥ 'yes' ç»§ç»­: ")
        if response.lower() != "yes":
            print("å–æ¶ˆæ“ä½œ")
            sys.exit(0)
    
    # è¿æ¥ Redis
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=True)
        r.ping()
    except Exception as e:
        print_error(f"Redis è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ„å»ºå¹¶å‘å¸ƒ trade_plan
    print("\nğŸ“¤ æ„å»º trade_plan...")
    event = build_trade_plan(
        symbol=args.symbol.upper(),
        timeframe=args.timeframe,
        side=args.side.upper(),
        entry_price=entry_price,
        sl_price=sl_price,
        env=settings.env,
    )
    
    plan_id = event["payload"]["plan_id"]
    idempotency_key = event["payload"]["idempotency_key"]
    
    print(f"   Plan ID: {plan_id}")
    print(f"   Idempotency Key: {idempotency_key}")
    
    print("\nğŸ“¨ å‘å¸ƒ trade_plan åˆ° Redis Streams...")
    msg_id = publish_event(r, "stream:trade_plan", event, event_type="TRADE_PLAN")
    print(f"   âœ… å·²å‘å¸ƒï¼Œæ¶ˆæ¯ ID: {msg_id}")
    
    # æ£€æŸ¥æ‰§è¡Œç»“æœ
    check_execution_result(r, plan_id, idempotency_key, wait_seconds=args.wait_seconds)
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ æç¤ºï¼š")
    print("   - æŸ¥çœ‹æ‰§è¡ŒæœåŠ¡æ—¥å¿—äº†è§£è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹")
    print("   - åœ¨ Bybit äº¤æ˜“æ‰€éªŒè¯è®¢å•æ˜¯å¦çœŸå®åˆ›å»º")
    print("   - å¦‚æœè®¢å•è¢«æ‹’ç»ï¼ŒæŸ¥çœ‹æ‰§è¡ŒæŠ¥å‘Šäº†è§£åŸå› ")

# ==================== æŸ¥çœ‹è®¢å•åŠŸèƒ½ ====================

def show_orders(idempotency_key: Optional[str] = None, limit: int = 10):
    """æ˜¾ç¤ºè®¢å•"""
    db_url = settings.database_url
    
    with get_conn(db_url) as conn:
        with conn.cursor() as cur:
            if idempotency_key:
                cur.execute("""
                    SELECT 
                        order_id,
                        idempotency_key,
                        symbol,
                        side,
                        order_type,
                        qty,
                        price,
                        status,
                        bybit_order_id,
                        created_at
                    FROM orders
                    WHERE idempotency_key = %s
                    ORDER BY created_at DESC
                    LIMIT %s;
                """, (idempotency_key, limit))
            else:
                cur.execute("""
                    SELECT 
                        order_id,
                        idempotency_key,
                        symbol,
                        side,
                        order_type,
                        qty,
                        price,
                        status,
                        bybit_order_id,
                        created_at
                    FROM orders
                    ORDER BY created_at DESC
                    LIMIT %s;
                """, (limit,))
            
            cols = [desc[0] for desc in cur.description]
            rows = cur.fetchall()
            
            if not rows:
                print("æ²¡æœ‰æ‰¾åˆ°è®¢å•")
                return
            
            # æ‰“å°è¡¨å¤´
            header = " | ".join(f"{col:20}" for col in cols)
            print(header)
            print("-" * len(header))
            
            # æ‰“å°æ•°æ®
            for row in rows:
                row_str = " | ".join(f"{str(v) if v is not None else 'NULL':20}" for v in row)
                print(row_str)

def cmd_orders(args):
    """æŸ¥çœ‹è®¢å•å‘½ä»¤"""
    print("=" * 60)
    print("  æŸ¥çœ‹è®¢å•")
    print("=" * 60)
    print()
    
    show_orders(idempotency_key=args.idempotency_key, limit=args.limit)

# ==================== è¯Šæ–­åŠŸèƒ½ ====================

def diagnose_order_failure(symbol: str, side: str):
    """è¯Šæ–­ä¸‹å•å¤±è´¥çš„åŸå› """
    print("=" * 60)
    print("  ä¸‹å•å¤±è´¥è¯Šæ–­")
    print("=" * 60)
    print()
    
    symbol_upper = symbol.upper()
    side_upper = side.upper()
    
    issues = []
    warnings = []
    
    # 1. æ£€æŸ¥æ•°æ®åº“ä¸­çš„ OPEN æŒä»“
    print_info("1. æ£€æŸ¥æ•°æ®åº“ä¸­çš„ OPEN æŒä»“...")
    db_positions = []
    with get_conn(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT 
                    position_id,
                    idempotency_key,
                    symbol,
                    timeframe,
                    side,
                    qty_total,
                    entry_price,
                    primary_sl_price,
                    status,
                    created_at
                FROM positions 
                WHERE status = 'OPEN' AND symbol = %s
                ORDER BY created_at DESC;
            """, (symbol_upper,))
            
            cols = [desc[0] for desc in cur.description]
            for row in cur.fetchall():
                db_positions.append(dict(zip(cols, row)))
    
    if db_positions:
        print_warning(f"   æ‰¾åˆ° {len(db_positions)} ä¸ªæ•°æ®åº“ä¸­çš„ OPEN æŒä»“:")
        for pos in db_positions:
            pos_side = pos.get("side", "").upper()
            print(f"     - {pos['position_id']}: {pos['symbol']} {pos_side} qty={pos['qty_total']}")
            
            # æ£€æŸ¥æ˜¯å¦åŒæ–¹å‘
            if pos_side == side_upper:
                issues.append(f"æ•°æ®åº“ä¸­å­˜åœ¨åŒæ–¹å‘ OPEN æŒä»“: {pos['position_id']} ({pos_side})")
    else:
        print_success("   æ•°æ®åº“ä¸­æ²¡æœ‰ OPEN æŒä»“")
    
    # 2. æ£€æŸ¥ Bybit äº¤æ˜“æ‰€çš„å®é™…æŒä»“
    print_info("\n2. æ£€æŸ¥ Bybit äº¤æ˜“æ‰€çš„å®é™…æŒä»“...")
    try:
        client = TradeRestV5Client(base_url=settings.bybit_rest_base_url)
        bybit_positions_resp = client.position_list(
            category=settings.bybit_category,
            symbol=symbol_upper
        )
        
        bybit_positions = []
        if bybit_positions_resp.get("retCode") == 0:
            result = bybit_positions_resp.get("result", {})
            bybit_list = result.get("list", [])
            
            for pos in bybit_list:
                size = float(pos.get("size", "0") or "0")
                if size > 0:
                    bybit_positions.append({
                        "symbol": pos.get("symbol", ""),
                        "side": pos.get("side", ""),
                        "size": size,
                        "entry_price": float(pos.get("avgPrice", "0") or "0"),
                        "mark_price": float(pos.get("markPrice", "0") or "0"),
                        "unrealised_pnl": float(pos.get("unrealisedPnl", "0") or "0"),
                    })
        
        if bybit_positions:
            print_warning(f"   Bybit äº¤æ˜“æ‰€ä¸­æœ‰ {len(bybit_positions)} ä¸ªå®é™…æŒä»“:")
            for pos in bybit_positions:
                bybit_side = pos.get("side", "").upper()
                print(f"     - {pos['symbol']} {bybit_side} size={pos['size']} entry={pos['entry_price']}")
                
                # æ£€æŸ¥æ˜¯å¦åŒæ–¹å‘
                if bybit_side == side_upper:
                    issues.append(f"Bybit äº¤æ˜“æ‰€å­˜åœ¨åŒæ–¹å‘æŒä»“: {pos['symbol']} {bybit_side} size={pos['size']}")
        else:
            print_success("   Bybit äº¤æ˜“æ‰€ä¸­æ²¡æœ‰æŒä»“")
            
        # æ£€æŸ¥æ•°æ®åº“å’Œäº¤æ˜“æ‰€çš„ä¸€è‡´æ€§
        if db_positions and not bybit_positions:
            warnings.append("æ•°æ®åº“ä¸­æœ‰ OPEN æŒä»“ï¼Œä½† Bybit äº¤æ˜“æ‰€ä¸­æ²¡æœ‰å¯¹åº”æŒä»“ï¼ˆå¯èƒ½æ˜¯è¿‡æœŸæŒä»“ï¼‰")
        elif not db_positions and bybit_positions:
            warnings.append("Bybit äº¤æ˜“æ‰€æœ‰æŒä»“ï¼Œä½†æ•°æ®åº“ä¸­æ²¡æœ‰å¯¹åº”è®°å½•ï¼ˆéœ€è¦åŒæ­¥ï¼‰")
            
    except Exception as e:
        print_error(f"   æ— æ³•è·å– Bybit æŒä»“: {e}")
        issues.append(f"æ— æ³•è¿æ¥ Bybit API: {e}")
    
    # 3. æ£€æŸ¥è´¦æˆ·ä½™é¢
    print_info("\n3. æ£€æŸ¥è´¦æˆ·ä½™é¢...")
    try:
        client = TradeRestV5Client(base_url=settings.bybit_rest_base_url)
        wallet_resp = client.wallet_balance(
            account_type=settings.bybit_account_type,
            coin="USDT"
        )
        
        if wallet_resp.get("retCode") == 0:
            result = wallet_resp.get("result", {})
            wallet_list = result.get("list", [])
            if wallet_list:
                coin_list = wallet_list[0].get("coin", [])
                for coin in coin_list:
                    if coin.get("coin") == "USDT":
                        available = float(coin.get("availableToWithdraw", "0") or "0")
                        equity = float(coin.get("equity", "0") or "0")
                        print_success(f"   USDT å¯ç”¨ä½™é¢: {available:.2f}")
                        print_info(f"   USDT æ€»æƒç›Š: {equity:.2f}")
                        
                        if available < 10:
                            warnings.append(f"è´¦æˆ·ä½™é¢è¾ƒä½: {available:.2f} USDT")
    except Exception as e:
        print_error(f"   æ— æ³•è·å–è´¦æˆ·ä½™é¢: {e}")
        warnings.append(f"æ— æ³•è·å–è´¦æˆ·ä½™é¢: {e}")
    
    # 4. æ£€æŸ¥é£é™©æ§åˆ¶è§„åˆ™
    print_info("\n4. æ£€æŸ¥é£é™©æ§åˆ¶è§„åˆ™...")
    print(f"   æœ€å¤§æŒä»“æ•°: {settings.max_open_positions}")
    print(f"   é£é™©ç™¾åˆ†æ¯”: {settings.risk_pct} ({settings.risk_pct * 100}%)")
    print(f"   è´¦æˆ·ç†”æ–­: {'å¯ç”¨' if settings.account_kill_switch_enabled else 'æœªå¯ç”¨'}")
    print(f"   é£é™©ç†”æ–­: {'å¯ç”¨' if settings.risk_circuit_enabled else 'æœªå¯ç”¨'}")
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æŒä»“æ•°
    if db_positions:
        total_open = len(db_positions)
        if total_open >= settings.max_open_positions:
            issues.append(f"å·²è¾¾åˆ°æœ€å¤§æŒä»“æ•°é™åˆ¶: {total_open}/{settings.max_open_positions}")
    
    # 5. æ£€æŸ¥æœ€è¿‘çš„æ‰§è¡ŒæŠ¥å‘Š
    print_info("\n5. æ£€æŸ¥æœ€è¿‘çš„æ‰§è¡ŒæŠ¥å‘Š...")
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=True)
        reports = r.xrevrange("stream:execution_report", max="+", min="-", count=10)
        
        recent_reports = []
        for msg_id, fields in reports:
            raw_data = fields.get("json") or fields.get("data")
            if raw_data:
                try:
                    evt = json.loads(raw_data)
                    payload = evt.get("payload", {})
                    if payload.get("symbol") == symbol_upper:
                        recent_reports.append({
                            "status": payload.get("status", ""),
                            "detail": payload.get("detail", {}),
                            "ts_ms": evt.get("ts_ms", 0),
                        })
                except Exception:
                    pass
        
        if recent_reports:
            print_warning(f"   æ‰¾åˆ° {len(recent_reports)} ä¸ªç›¸å…³æ‰§è¡ŒæŠ¥å‘Š:")
            for rep in recent_reports[:3]:
                status = rep.get("status", "")
                detail = rep.get("detail", {})
                reason = detail.get("reason") or detail.get("error") or "æ— è¯¦æƒ…"
                print(f"     - çŠ¶æ€: {status}, åŸå› : {reason}")
        else:
            print_success("   æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ‰§è¡ŒæŠ¥å‘Š")
    except Exception as e:
        print_error(f"   æ— æ³•æ£€æŸ¥æ‰§è¡ŒæŠ¥å‘Š: {e}")
    
    # 6. æ€»ç»“å’Œå»ºè®®
    print("\n" + "=" * 60)
    print("  è¯Šæ–­æ€»ç»“")
    print("=" * 60)
    
    if issues:
        print_error("\nâŒ å‘ç°çš„é—®é¢˜ï¼ˆå¯èƒ½å¯¼è‡´ä¸‹å•å¤±è´¥ï¼‰:")
        for i, issue in enumerate(issues, 1):
            print(f"   {i}. {issue}")
    else:
        print_success("\nâœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")
    
    if warnings:
        print_warning("\nâš ï¸  è­¦å‘Š:")
        for i, warning in enumerate(warnings, 1):
            print(f"   {i}. {warning}")
    
    # æä¾›ä¿®å¤å»ºè®®
    print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
    if any("åŒæ–¹å‘" in issue for issue in issues):
        print("   1. æ¸…ç†åŒæ–¹å‘çš„ OPEN æŒä»“:")
        print(f"      python -m scripts.trading_test_tool clean --all")
        print("   2. æˆ–è€…å…³é—­ç‰¹å®šæŒä»“:")
        print(f"      python -m scripts.trading_test_tool clean <position_id>")
    
    if any("æœ€å¤§æŒä»“æ•°" in issue for issue in issues):
        print("   1. å…³é—­éƒ¨åˆ†æŒä»“ä»¥é‡Šæ”¾é¢åº¦")
        print("   2. æˆ–å¢åŠ  MAX_OPEN_POSITIONS é…ç½®")
    
    if any("è¿‡æœŸæŒä»“" in warning for warning in warnings):
        print("   1. æ¸…ç†æ•°æ®åº“ä¸­çš„è¿‡æœŸæŒä»“:")
        print(f"      python -m scripts.trading_test_tool clean --all")
    
    if not issues and not warnings:
        print("   ç³»ç»ŸçŠ¶æ€æ­£å¸¸ï¼Œå¦‚æœä»ç„¶æ— æ³•ä¸‹å•ï¼Œè¯·æ£€æŸ¥:")
        print("   1. æ‰§è¡ŒæœåŠ¡æ—¥å¿—: docker compose logs execution | tail -50")
        print("   2. é£é™©äº‹ä»¶: æ£€æŸ¥ stream:risk_event")
        print("   3. è´¦æˆ·æƒé™: ç¡®è®¤ API Key æœ‰äº¤æ˜“æƒé™")

def cmd_diagnose(args):
    """è¯Šæ–­ä¸‹å•å¤±è´¥å‘½ä»¤"""
    diagnose_order_failure(args.symbol, args.side)

def cmd_quick_test(args):
    """å¿«é€Ÿæµ‹è¯•ä¸‹å•å‘½ä»¤ï¼ˆæ•´åˆ quick_test_order.sh åŠŸèƒ½ï¼‰"""
    # ä½¿ç”¨é»˜è®¤å‚æ•°æˆ–ç”¨æˆ·æŒ‡å®šçš„å‚æ•°
    symbol = args.symbol.upper()
    side = args.side.upper()
    timeframe = args.timeframe
    sl_distance_pct = args.sl_distance_pct
    
    print("=" * 60)
    print("  å¿«é€Ÿæµ‹è¯•ä¸‹å•")
    print("=" * 60)
    print()
    print(f"äº¤æ˜“å¯¹: {symbol}")
    print(f"æ–¹å‘: {side}")
    print(f"æ—¶é—´æ¡†æ¶: {timeframe}")
    print()
    
    # è°ƒç”¨ test å‘½ä»¤
    test_args = argparse.Namespace(
        symbol=symbol,
        side=side,
        entry_price=None,
        sl_price=None,
        sl_distance_pct=sl_distance_pct,
        timeframe=timeframe,
        wait_seconds=args.wait_seconds,
        confirm=True,  # å¿«é€Ÿæµ‹è¯•é»˜è®¤è·³è¿‡ç¡®è®¤
        auto_diagnose=True,  # é»˜è®¤å¯ç”¨è‡ªåŠ¨è¯Šæ–­
    )
    cmd_test(test_args)

def cmd_diagnose_signals(args):
    """è¯Šæ–­ä¿¡å·ç”Ÿæˆé—®é¢˜å‘½ä»¤"""
    # ç›´æ¥åœ¨è¿™é‡Œå®ç°è¯Šæ–­é€»è¾‘ï¼Œé¿å…å¯¼å…¥é—®é¢˜
    from services.strategy.repo import get_bars
    from libs.strategy.divergence import detect_three_segment_divergence
    from libs.strategy.confluence import Candle, vegas_state, engulfing, rsi_divergence, obv_divergence, fvg_proximity
    
    symbol = args.symbol.upper()
    timeframe = args.timeframe
    
    print("\n" + "=" * 80)
    print("  ä¿¡å·ç”Ÿæˆè¯Šæ–­å·¥å…·".center(80))
    print("=" * 80)
    
    # 1. æ£€æŸ¥å¸‚åœºæ•°æ®
    print("\n" + "=" * 80)
    print("  1. å¸‚åœºæ•°æ®æ£€æŸ¥")
    print("=" * 80)
    
    bars = get_bars(settings.database_url, symbol=symbol, timeframe=timeframe, limit=500)
    bar_count = len(bars)
    
    print_info(f"äº¤æ˜“å¯¹: {symbol}, æ—¶é—´æ¡†æ¶: {timeframe}")
    print_info(f"K çº¿æ•°é‡: {bar_count}")
    
    if bar_count < 120:
        print_error(f"K çº¿æ•°é‡ä¸è¶³ï¼éœ€è¦è‡³å°‘ 120 æ ¹ï¼Œå½“å‰åªæœ‰ {bar_count} æ ¹")
        print_warning("ä¿¡å·ç”Ÿæˆéœ€è¦è‡³å°‘ 120 æ ¹ K çº¿æ‰èƒ½è¿›è¡Œä¸‰æ®µèƒŒç¦»æ£€æµ‹")
        return
    
    print_success(f"K çº¿æ•°é‡è¶³å¤Ÿï¼ˆ{bar_count} >= 120ï¼‰")
    
    if bars:
        latest = bars[-1]
        print_info(f"æœ€æ–° K çº¿æ—¶é—´: {latest['close_time_ms']}")
        print_info(f"æœ€æ–°æ”¶ç›˜ä»·: {latest['close']}")
    
    # 2. æ£€æŸ¥ä¸‰æ®µèƒŒç¦»
    print("\n" + "=" * 80)
    print("  2. ä¸‰æ®µèƒŒç¦»æ£€æµ‹")
    print("=" * 80)
    
    candles = [Candle(open=b["open"], high=b["high"], low=b["low"], close=b["close"], volume=b["volume"]) for b in bars]
    close = [c.close for c in candles]
    high = [c.high for c in candles]
    low = [c.low for c in candles]
    
    setup = detect_three_segment_divergence(close=close, high=high, low=low)
    
    if setup is None:
        print_warning("æœªæ£€æµ‹åˆ°ä¸‰æ®µèƒŒç¦»")
        print_info("ä¸‰æ®µèƒŒç¦»æ˜¯ä¿¡å·ç”Ÿæˆçš„å‰ææ¡ä»¶")
        print_info("éœ€è¦ MACD histogram å½¢æˆä¸‰æ®µé¡¶/åº•èƒŒç¦»ç»“æ„")
        return
    
    print_success(f"æ£€æµ‹åˆ°ä¸‰æ®µèƒŒç¦»ï¼æ–¹å‘: {setup.direction}")
    print_info(f"  P1: index={setup.p1.index}, price={setup.p1.price:.2f}, hist={setup.h1:.4f}")
    print_info(f"  P2: index={setup.p2.index}, price={setup.p2.price:.2f}, hist={setup.h2:.4f}")
    print_info(f"  P3: index={setup.p3.index}, price={setup.p3.price:.2f}, hist={setup.h3:.4f}")
    
    bias = setup.direction
    
    # 3. æ£€æŸ¥ Vegas
    print("\n" + "=" * 80)
    print("  3. Vegas çŠ¶æ€æ£€æŸ¥")
    print("=" * 80)
    
    vs = vegas_state(close)
    print_info(f"å½“å‰ Vegas çŠ¶æ€: {vs}")
    print_info(f"ä¿¡å·æ–¹å‘: {bias}")
    
    if bias == "LONG" and vs != "Bullish":
        print_error(f"Vegas çŠ¶æ€ä¸åŒ¹é…ï¼LONG ä¿¡å·éœ€è¦ Bullishï¼Œä½†å½“å‰æ˜¯ {vs}")
        return
    
    if bias == "SHORT" and vs != "Bearish":
        print_error(f"Vegas çŠ¶æ€ä¸åŒ¹é…ï¼SHORT ä¿¡å·éœ€è¦ Bearishï¼Œä½†å½“å‰æ˜¯ {vs}")
        return
    
    print_success(f"Vegas çŠ¶æ€åŒ¹é…ï¼ˆ{bias} éœ€è¦ {vs}ï¼‰")
    
    # 4. æ£€æŸ¥ç¡®è®¤é¡¹
    print("\n" + "=" * 80)
    print("  4. ç¡®è®¤é¡¹æ£€æŸ¥")
    print("=" * 80)
    
    hits = []
    
    if engulfing(candles[-2:], bias):
        hits.append("ENGULFING")
        print_success("âœ… ENGULFINGï¼ˆåæ²¡å½¢æ€ï¼‰")
    else:
        print_warning("âŒ ENGULFINGï¼ˆåæ²¡å½¢æ€ï¼‰æœªå‘½ä¸­")
    
    if rsi_divergence(candles, bias):
        hits.append("RSI_DIV")
        print_success("âœ… RSI_DIVï¼ˆRSI èƒŒç¦»ï¼‰")
    else:
        print_warning("âŒ RSI_DIVï¼ˆRSI èƒŒç¦»ï¼‰æœªå‘½ä¸­")
    
    if obv_divergence(candles, bias):
        hits.append("OBV_DIV")
        print_success("âœ… OBV_DIVï¼ˆOBV èƒŒç¦»ï¼‰")
    else:
        print_warning("âŒ OBV_DIVï¼ˆOBV èƒŒç¦»ï¼‰æœªå‘½ä¸­")
    
    if fvg_proximity(candles, bias):
        hits.append("FVG_PROXIMITY")
        print_success("âœ… FVG_PROXIMITYï¼ˆFVG æ¥è¿‘ï¼‰")
    else:
        print_warning("âŒ FVG_PROXIMITYï¼ˆFVG æ¥è¿‘ï¼‰æœªå‘½ä¸­")
    
    print_info(f"\nå‘½ä¸­ç¡®è®¤é¡¹æ•°é‡: {len(hits)}/{4}")
    print_info(f"éœ€è¦çš„æœ€å°ç¡®è®¤é¡¹: {settings.min_confirmations}")
    print_info(f"å‘½ä¸­çš„ç¡®è®¤é¡¹: {hits if hits else 'æ— '}")
    
    if len(hits) < settings.min_confirmations:
        print_error(f"ç¡®è®¤é¡¹ä¸è¶³ï¼éœ€è¦è‡³å°‘ {settings.min_confirmations} ä¸ªï¼Œä½†åªå‘½ä¸­ {len(hits)} ä¸ª")
        return
    
    print_success(f"ç¡®è®¤é¡¹è¶³å¤Ÿï¼ˆ{len(hits)} >= {settings.min_confirmations}ï¼‰")
    
    # 5. æ£€æŸ¥æœåŠ¡çŠ¶æ€
    print("\n" + "=" * 80)
    print("  5. ç­–ç•¥æœåŠ¡çŠ¶æ€æ£€æŸ¥")
    print("=" * 80)
    
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=True)
        r.ping()
        print_success("Redis è¿æ¥æ­£å¸¸")
    except Exception as e:
        print_error(f"Redis è¿æ¥å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥ bar_close äº‹ä»¶
    try:
        msgs = r.xrevrange("stream:bar_close", "+", "-", count=5)
        if msgs:
            print_success(f"æœ€è¿‘æœ‰ {len(msgs)} ä¸ª bar_close äº‹ä»¶")
        else:
            print_warning("æ²¡æœ‰ bar_close äº‹ä»¶ï¼")
            print_warning("å¯èƒ½åŸå› ï¼š")
            print_warning("  1. marketdata æœåŠ¡æœªè¿è¡Œ")
            print_warning("  2. æ²¡æœ‰è®¢é˜…çš„äº¤æ˜“å¯¹")
            print_warning("  3. å¸‚åœºæ•°æ®æœªæ­£å¸¸æ¥æ”¶")
    except Exception as e:
        print_warning(f"æ£€æŸ¥ bar_close äº‹ä»¶å¤±è´¥: {e}")
    
    # æ£€æŸ¥ä¿¡å·äº‹ä»¶
    try:
        msgs = r.xrevrange("stream:signal", "+", "-", count=5)
        if msgs:
            print_warning(f"æœ€è¿‘æœ‰ {len(msgs)} ä¸ªä¿¡å·äº‹ä»¶ï¼ˆè¯´æ˜ä¹‹å‰æœ‰ä¿¡å·ç”Ÿæˆï¼‰")
        else:
            print_info("æ²¡æœ‰ä¿¡å·äº‹ä»¶ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœå½“å‰æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ä¿¡å·ï¼‰")
    except Exception as e:
        print_warning(f"æ£€æŸ¥ä¿¡å·äº‹ä»¶å¤±è´¥: {e}")
    
    # 6. æ£€æŸ¥æ•°æ®åº“ä¿¡å·
    print("\n" + "=" * 80)
    print("  6. æ•°æ®åº“ä¿¡å·æ£€æŸ¥")
    print("=" * 80)
    
    try:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT signal_id, symbol, timeframe, bias, hit_count, hits, vegas_state, created_at
                    FROM signals
                    WHERE symbol = %s AND timeframe = %s
                    ORDER BY created_at DESC
                    LIMIT 10
                """, (symbol, timeframe))
                
                rows = cur.fetchall()
                
                if rows:
                    print_success(f"æ‰¾åˆ° {len(rows)} ä¸ªå†å²ä¿¡å·")
                    print_info("\næœ€è¿‘çš„ä¿¡å·ï¼š")
                    for i, row in enumerate(rows[:5], 1):
                        print(f"  {i}. {row[3]} | hits={row[4]} | {row[6]} | {row[7]}")
                else:
                    print_warning(f"æ•°æ®åº“ä¸­æ²¡æœ‰ {symbol} {timeframe} çš„ä¿¡å·è®°å½•")
    except Exception as e:
        print_error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
    
    # 7. æ£€æŸ¥é…ç½®
    print("\n" + "=" * 80)
    print("  7. é…ç½®æ£€æŸ¥")
    print("=" * 80)
    
    print_info(f"MIN_CONFIRMATIONS: {settings.min_confirmations}")
    print_info(f"AUTO_TIMEFRAMES: {settings.auto_timeframes}")
    print_info(f"MONITOR_TIMEFRAMES: {settings.monitor_timeframes}")
    
    auto_tfs = [x.strip() for x in settings.auto_timeframes.split(",") if x.strip()]
    monitor_tfs = [x.strip() for x in settings.monitor_timeframes.split(",") if x.strip()]
    
    print_info(f"\nè‡ªåŠ¨ä¸‹å•æ—¶é—´æ¡†æ¶: {auto_tfs}")
    print_info(f"ç›‘æ§æ—¶é—´æ¡†æ¶: {monitor_tfs}")
    print_info("æ³¨æ„ï¼šåªæœ‰ AUTO_TIMEFRAMES ä¸­çš„æ—¶é—´æ¡†æ¶ä¼šç”Ÿæˆ trade_plan")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("  è¯Šæ–­æ€»ç»“".center(80))
    print("=" * 80)
    print_success("æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼Œåº”è¯¥å¯ä»¥ç”Ÿæˆä¿¡å·ï¼")
    print_info("å¦‚æœä»ç„¶æ²¡æœ‰ä¿¡å·ï¼Œå¯èƒ½çš„åŸå› ï¼š")
    print_info("  1. ç­–ç•¥æœåŠ¡æœªæ­£å¸¸è¿è¡Œ")
    print_info("  2. bar_close äº‹ä»¶æœªæ­£å¸¸æ¥æ”¶")
    print_info("  3. ä¿¡å·å·²ç”Ÿæˆä½†è¢«å…¶ä»–æ¡ä»¶è¿‡æ»¤")
    print_info("\nå»ºè®®ï¼š")
    print_info("  1. æ£€æŸ¥ç­–ç•¥æœåŠ¡æ—¥å¿—: docker compose logs strategy --tail 100")
    print_info("  2. æ£€æŸ¥å¸‚åœºæ•°æ®æœåŠ¡: docker compose logs marketdata --tail 100")
    print_info("  3. æ£€æŸ¥ Redis Streams ä¸­çš„ bar_close äº‹ä»¶")

# ==================== æŒä»“åŒæ­¥åŠŸèƒ½ ====================

def sync_positions_with_exchange(dry_run: bool = False) -> Dict[str, Any]:
    """åŒæ­¥æ•°æ®åº“æŒä»“ä¸äº¤æ˜“æ‰€æŒä»“"""
    print("=" * 60)
    print("  æŒä»“åŒæ­¥æ£€æŸ¥")
    print("=" * 60)
    print()
    
    if str(settings.execution_mode).upper() != "LIVE":
        print_error("æŒä»“åŒæ­¥ä»…åœ¨ LIVE æ¨¡å¼ä¸‹å¯ç”¨")
        return {"synced": 0, "errors": 0, "skipped": 0}
    
    try:
        from services.execution.position_sync import sync_positions
    except ImportError:
        print_error("æ— æ³•å¯¼å…¥ position_sync æ¨¡å—")
        return {"synced": 0, "errors": 0, "skipped": 0}
    
    print_info("æ­£åœ¨æ£€æŸ¥æ•°æ®åº“ä¸­çš„ OPEN æŒä»“...")
    
    # è·å–æ‰€æœ‰ OPEN æŒä»“
    db_positions = []
    with get_conn(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT 
                    position_id,
                    idempotency_key,
                    symbol,
                    timeframe,
                    side,
                    qty_total,
                    entry_price,
                    status,
                    created_at
                FROM positions 
                WHERE status = 'OPEN'
                ORDER BY created_at DESC;
            """)
            
            cols = [desc[0] for desc in cur.description]
            for row in cur.fetchall():
                db_positions.append(dict(zip(cols, row)))
    
    if not db_positions:
        print_success("æ•°æ®åº“ä¸­æ²¡æœ‰ OPEN æŒä»“ï¼Œæ— éœ€åŒæ­¥")
        return {"synced": 0, "errors": 0, "skipped": 0}
    
    print_info(f"æ‰¾åˆ° {len(db_positions)} ä¸ªæ•°æ®åº“ä¸­çš„ OPEN æŒä»“")
    print()
    
    # æ£€æŸ¥æ¯ä¸ªæŒä»“åœ¨äº¤æ˜“æ‰€çš„çŠ¶æ€
    client = TradeRestV5Client(base_url=settings.bybit_rest_base_url)
    synced_count = 0
    error_count = 0
    skipped_count = 0
    
    for pos in db_positions:
        symbol = pos["symbol"]
        position_id = pos["position_id"]
        idem = pos["idempotency_key"]
        
        print_info(f"æ£€æŸ¥æŒä»“: {position_id} ({symbol})")
        
        try:
            # æŸ¥è¯¢äº¤æ˜“æ‰€æŒä»“
            bybit_resp = client.position_list(
                category=settings.bybit_category,
                symbol=symbol
            )
            
            if bybit_resp.get("retCode") != 0:
                print_error(f"  æŸ¥è¯¢å¤±è´¥: {bybit_resp.get('retMsg', 'æœªçŸ¥é”™è¯¯')}")
                error_count += 1
                continue
            
            result = bybit_resp.get("result", {})
            bybit_list = result.get("list", [])
            
            # æŸ¥æ‰¾å¯¹åº”æŒä»“
            exchange_size = 0.0
            exchange_side = None
            if bybit_list:
                for bp in bybit_list:
                    size = float(bp.get("size", "0") or "0")
                    if size > 0:
                        exchange_size = size
                        exchange_side = bp.get("side", "")
                        break
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦åŒæ­¥
            if exchange_size == 0:
                # äº¤æ˜“æ‰€ä¸­æ²¡æœ‰æŒä»“ï¼Œä½†æ•°æ®åº“ä¸­æ˜¯ OPENï¼Œéœ€è¦å…³é—­
                print_warning(f"  âš ï¸  äº¤æ˜“æ‰€ä¸­å·²å¹³ä»“ï¼Œä½†æ•°æ®åº“ä¸­ä»ä¸º OPEN")
                print(f"     æ•°æ®åº“çŠ¶æ€: OPEN, qty={pos['qty_total']}")
                print(f"     äº¤æ˜“æ‰€çŠ¶æ€: å·²å¹³ä»“ (size=0)")
                
                if not dry_run:
                    # ç›´æ¥æ›´æ–°æ•°æ®åº“çŠ¶æ€
                    try:
                        from services.execution.repo import mark_position_closed
                        from libs.common.time import now_ms
                        
                        meta = dict(pos.get("meta") or {})
                        exit_reason = "MANUAL_CLOSE"  # æ‰‹åŠ¨å¹³ä»“
                        
                        mark_position_closed(
                            database_url=settings.database_url,
                            position_id=position_id,
                            closed_at_ms=now_ms(),
                            exit_reason=exit_reason,
                            meta=meta
                        )
                        
                        print_success(f"  âœ… å·²åŒæ­¥ï¼šå°†æ•°æ®åº“çŠ¶æ€æ›´æ–°ä¸º CLOSED (exit_reason={exit_reason})")
                        synced_count += 1
                    except Exception as e:
                        print_error(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
                        error_count += 1
                else:
                    print_info(f"  [DRY RUN] å°†æ›´æ–°ä¸º CLOSED (exit_reason=MANUAL_CLOSE)")
                    skipped_count += 1
            else:
                # äº¤æ˜“æ‰€ä¸­ä»æœ‰æŒä»“
                print_success(f"  âœ… çŠ¶æ€ä¸€è‡´ï¼šäº¤æ˜“æ‰€ä¸­ä»æœ‰æŒä»“ (size={exchange_size}, side={exchange_side})")
                skipped_count += 1
                
        except Exception as e:
            print_error(f"  âŒ æ£€æŸ¥å¤±è´¥: {e}")
            error_count += 1
        
        print()
    
    # æ€»ç»“
    print("=" * 60)
    print("  åŒæ­¥ç»“æœ")
    print("=" * 60)
    print(f"  å·²åŒæ­¥: {synced_count}")
    print(f"  è·³è¿‡: {skipped_count}")
    print(f"  é”™è¯¯: {error_count}")
    
    if dry_run:
        print()
        print_info("è¿™æ˜¯ DRY RUN æ¨¡å¼ï¼Œæœªå®é™…ä¿®æ”¹æ•°æ®åº“")
        print("  è¿è¡Œä¸å¸¦ --dry-run å‚æ•°æ¥å®é™…æ‰§è¡ŒåŒæ­¥")
    
    return {
        "synced": synced_count,
        "skipped": skipped_count,
        "errors": error_count,
        "total": len(db_positions)
    }

def cmd_sync(args):
    """æŒä»“åŒæ­¥å‘½ä»¤"""
    sync_positions_with_exchange(dry_run=args.dry_run)

# ==================== å¹³ä»“æµ‹è¯•åŠŸèƒ½ ====================

def cmd_close_test(args):
    """å¹³ä»“æµ‹è¯•å‘½ä»¤ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰"""
    print("=" * 60)
    print("  å¹³ä»“æµ‹è¯•ï¼ˆE2E Stage 2ï¼‰")
    print("=" * 60)
    print()
    
    mode = str(settings.execution_mode).upper()
    if mode not in ("PAPER", "BACKTEST"):
        print_warning(f"å½“å‰æ¨¡å¼: {mode}ï¼Œå»ºè®®ä½¿ç”¨ PAPER æˆ– BACKTEST æ¨¡å¼")
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ")
        if response.lower() != "yes":
            return
    
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=True)
        r.ping()
    except Exception as e:
        print_error(f"Redis è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ„å»º trade_plan
    symbol = args.symbol.upper()
    timeframe = args.timeframe
    side = args.side.upper()
    entry_price = args.entry_price
    sl_price = args.sl_price
    
    print_info("æ„å»º trade_plan...")
    event = build_trade_plan(
        symbol=symbol,
        timeframe=timeframe,
        side=side,
        entry_price=entry_price,
        sl_price=sl_price,
        env=settings.env,
    )
    
    plan_id = event["payload"]["plan_id"]
    idem = event["payload"]["idempotency_key"]
    
    print_success(f"Plan ID: {plan_id}")
    print_success(f"Idempotency Key: {idem}")
    
    # å‘å¸ƒ trade_plan
    print_info("å‘å¸ƒ trade_plan åˆ° Redis Streams...")
    msg_id = publish_event(r, "stream:trade_plan", event, event_type="TRADE_PLAN")
    print_success(f"å·²å‘å¸ƒï¼Œæ¶ˆæ¯ ID: {msg_id}")
    
    # ç­‰å¾…æŒä»“åˆ›å»º
    print_info(f"ç­‰å¾… {args.wait_before_close} ç§’è®©æŒä»“åˆ›å»º...")
    time.sleep(args.wait_before_close)
    
    # å¼ºåˆ¶å¹³ä»“
    print_info("å¼ºåˆ¶å¹³ä»“ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰...")
    try:
        from services.execution.executor import close_position_market
        
        close_position_market(
            database_url=settings.database_url,
            redis_url=settings.redis_url,
            idempotency_key=idem,
            symbol=symbol,
            side=side,
            close_price=args.close_price,
            close_time_ms=now_ms(),
            reason="close_test_force_close",
        )
        print_success("å¹³ä»“è¯·æ±‚å·²å‘é€")
    except Exception as e:
        print_error(f"å¹³ä»“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # ç­‰å¾…æŠ¥å‘Šç”Ÿæˆ
    print_info(f"ç­‰å¾… {args.wait_after_close} ç§’è®©æŠ¥å‘Šç”Ÿæˆ...")
    time.sleep(args.wait_after_close)
    
    # æ£€æŸ¥æ‰§è¡ŒæŠ¥å‘Š
    print_info("æ£€æŸ¥æ‰§è¡ŒæŠ¥å‘Š...")
    reports = r.xrevrange("stream:execution_report", max="+", min="-", count=200)
    related_reports = []
    for msg_id, fields in reports:
        raw_data = fields.get("json") or fields.get("data")
        if raw_data:
            try:
                evt = json.loads(raw_data)
                payload = evt.get("payload", {})
                if payload.get("plan_id") == plan_id or payload.get("idempotency_key") == idem:
                    related_reports.append(evt)
            except Exception:
                pass
    
    if related_reports:
        print_success(f"æ‰¾åˆ° {len(related_reports)} ä¸ªç›¸å…³æ‰§è¡ŒæŠ¥å‘Š:")
        for i, rep in enumerate(related_reports[:10], 1):
            payload = rep.get("payload", {})
            print(f"  {i}. {payload.get('status')} - {payload.get('symbol')}")
            detail = payload.get("detail", {})
            if isinstance(detail, dict):
                pnl = detail.get("pnl_usdt")
                if pnl is not None:
                    print(f"     PnL: {pnl:.2f} USDT")
    else:
        print_warning("æœªæ‰¾åˆ°ç›¸å…³æ‰§è¡ŒæŠ¥å‘Š")
    
    # æ£€æŸ¥é£é™©äº‹ä»¶
    print_info("æ£€æŸ¥é£é™©äº‹ä»¶...")
    risk_events = r.xrevrange("stream:risk_event", max="+", min="-", count=50)
    related_risks = []
    for msg_id, fields in risk_events:
        raw_data = fields.get("json") or fields.get("data")
        if raw_data:
            try:
                evt = json.loads(raw_data)
                payload = evt.get("payload", {})
                detail = payload.get("detail", {})
                if isinstance(detail, dict):
                    if detail.get("idempotency_key") == idem:
                        related_risks.append(evt)
            except Exception:
                pass
    
    if related_risks:
        print_warning(f"æ‰¾åˆ° {len(related_risks)} ä¸ªç›¸å…³é£é™©äº‹ä»¶")
    else:
        print_success("æœªæ‰¾åˆ°ç›¸å…³é£é™©äº‹ä»¶")
    
    print()
    print_success("å¹³ä»“æµ‹è¯•å®Œæˆï¼")
    print_info("å¦‚æœé…ç½®äº† Telegramï¼Œåº”è¯¥ä¼šæ”¶åˆ°åŒ…å« PnL å’Œè¿ç»­äºæŸç»Ÿè®¡çš„å¹³ä»“æ¶ˆæ¯")

# ==================== é£æ§æµ‹è¯•åŠŸèƒ½ ====================

def cmd_gates_test(args):
    """é£æ§é—¸é—¨æµ‹è¯•å‘½ä»¤ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰"""
    print("=" * 60)
    print("  é£æ§é—¸é—¨æµ‹è¯•ï¼ˆE2E Stage 6ï¼‰")
    print("=" * 60)
    print()
    
    mode = str(settings.execution_mode).upper()
    if mode not in ("PAPER", "BACKTEST"):
        print_warning(f"å½“å‰æ¨¡å¼: {mode}ï¼Œå»ºè®®ä½¿ç”¨ PAPER æˆ– BACKTEST æ¨¡å¼")
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ")
        if response.lower() != "yes":
            return
    
    try:
        r = redis.Redis.from_url(settings.redis_url, decode_responses=False)
        r.ping()
    except Exception as e:
        print_error(f"Redis è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # é‡ç½®æ•°æ®åº“ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.reset_db:
        print_warning("é‡ç½®æ•°æ®åº“ï¼ˆTRUNCATE execution tablesï¼‰...")
        try:
            import psycopg
            with psycopg.connect(settings.database_url) as conn:
                with conn.cursor() as cur:
                    cur.execute("TRUNCATE TABLE orders, positions, cooldowns, execution_reports, risk_events, backtest_trades RESTART IDENTITY CASCADE;")
                conn.commit()
            print_success("æ•°æ®åº“å·²é‡ç½®")
            time.sleep(1)
        except Exception as e:
            print_error(f"é‡ç½®æ•°æ®åº“å¤±è´¥: {e}")
            sys.exit(1)
    
    def _xlast(stream: str) -> str:
        try:
            xs = r.xrevrange(stream, count=1)
            if xs:
                return xs[0][0].decode() if isinstance(xs[0][0], (bytes, bytearray)) else str(xs[0][0])
        except Exception:
            pass
        return "0-0"
    
    def _collect(stream: str, start_id: str, predicate, timeout_s: int = 15) -> List[Dict[str, Any]]:
        end = time.time() + timeout_s
        cur = start_id
        out: List[Dict[str, Any]] = []
        while time.time() < end:
            resp = r.xread({stream: cur}, count=100, block=500)
            if not resp:
                continue
            for _stream_name, items in resp:
                for xid, fields in items:
                    cur = xid.decode() if isinstance(xid, (bytes, bytearray)) else str(xid)
                    raw = fields.get(b"json") or fields.get("json")
                    if raw is None:
                        continue
                    try:
                        obj = json.loads(raw.decode() if isinstance(raw, (bytes, bytearray)) else raw)
                    except Exception:
                        continue
                    if predicate(obj):
                        out.append(obj)
            if out:
                break
        return out
    
    def _build_trade_plan(symbol: str, timeframe: str, side: str, entry: float, sl: float, close_time_ms: int) -> Dict[str, Any]:
        plan_id = f"stage6-{uuid.uuid4().hex[:10]}"
        idem = f"idem-{uuid.uuid4().hex}"
        return {
            "event_id": f"evt-{uuid.uuid4().hex}",
            "ts_ms": now_ms(),
            "env": settings.env,
            "service": "e2e-stage6",
            "payload": {
                "plan_id": plan_id,
                "idempotency_key": idem,
                "symbol": symbol,
                "timeframe": timeframe,
                "side": side,
                "entry_price": float(entry),
                "primary_sl_price": float(sl),
                "risk_pct": 0.005,
                "close_time_ms": int(close_time_ms),
                "tp_rules": {
                    "tp1": {"r": 1.0, "pct": 0.4},
                    "tp2": {"r": 2.0, "pct": 0.4},
                    "tp3_trail": {"pct": 0.2, "mode": "ATR"},
                    "reduce_only": True,
                },
                "secondary_sl_rule": {"type": "NEXT_BAR_NOT_SHORTEN_EXIT"},
                "traceability": {"setup_id": "stage6", "trigger_id": "stage6"},
                "ext": {"run_id": "stage6-test"},
            },
        }
    
    def _build_bar_close(symbol: str, timeframe: str, close_time_ms: int, o: float, h: float, l: float, c: float) -> Dict[str, Any]:
        return {
            "event_id": f"evt-{uuid.uuid4().hex}",
            "ts_ms": now_ms(),
            "env": settings.env,
            "service": "e2e-stage6",
            "payload": {
                "symbol": symbol,
                "timeframe": timeframe,
                "close_time_ms": int(close_time_ms),
                "is_final": True,
                "source": "bybit_ws",
                "ohlcv": {"open": float(o), "high": float(h), "low": float(l), "close": float(c), "volume": 1.0},
                "ext": {"run_id": "stage6-test"},
            },
        }
    
    # æµ‹è¯•1: MAX_POSITIONS_BLOCKED
    print_info("[T1] æµ‹è¯•æœ€å¤§æŒä»“æ•°é™åˆ¶ï¼ˆç¬¬4ä¸ªåº”è¯¥è¢«æ‹’ç»ï¼‰...")
    start_rep = _xlast("stream:execution_report")
    start_risk = _xlast("stream:risk_event")
    base_t = now_ms()
    syms = ["BTCUSDT", "ETHUSDT", "BCHUSDT", "LTCUSDT"]
    idems: List[str] = []
    
    for i, s in enumerate(syms):
        ev = _build_trade_plan(symbol=s, timeframe="1h", side="BUY", entry=100 + i, sl=90 + i, close_time_ms=base_t + i * 3600000)
        idems.append(ev["payload"]["idempotency_key"])
        publish_event(r, "stream:trade_plan", ev, event_type="trade_plan")
        time.sleep(0.2)
    
    rejected = _collect(
        "stream:execution_report",
        start_rep,
        lambda obj: (obj.get("payload") or {}).get("idempotency_key") == idems[-1]
        and str((obj.get("payload") or {}).get("status") or "").upper() in ("REJECTED", "ORDER_REJECTED", "ERROR"),
        timeout_s=args.wait,
    )
    if not rejected:
        print_error("T1 å¤±è´¥: ç¬¬4ä¸ªè®¡åˆ’æœªè¢«æ‹’ç»")
        sys.exit(1)
    print_success("T1 é€šè¿‡: ç¬¬4ä¸ªè®¡åˆ’è¢«æ­£ç¡®æ‹’ç»")
    
    risk_max = _collect(
        "stream:risk_event",
        start_risk,
        lambda obj: str((obj.get("payload") or {}).get("type") or "").upper() == "MAX_POSITIONS_BLOCKED",
        timeout_s=args.wait,
    )
    if not risk_max:
        print_error("T1 å¤±è´¥: æœªç”Ÿæˆ MAX_POSITIONS_BLOCKED é£é™©äº‹ä»¶")
        sys.exit(1)
    print_success("T1 é€šè¿‡: ç”Ÿæˆäº† MAX_POSITIONS_BLOCKED é£é™©äº‹ä»¶")
    
    # æµ‹è¯•2: mutex upgrade
    print_info("[T2] æµ‹è¯•åŒå¸ç§åŒå‘äº’æ–¥å‡çº§ï¼ˆ4h åº”è¯¥å…³é—­ 1h å¹¶å¼€æ–°ä»“ï¼‰...")
    if args.reset_db:
        import psycopg
        with psycopg.connect(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute("TRUNCATE TABLE orders, positions, cooldowns, execution_reports, risk_events, backtest_trades RESTART IDENTITY CASCADE;")
            conn.commit()
        time.sleep(1)
    
    start_rep = _xlast("stream:execution_report")
    base_t = now_ms()
    ev1 = _build_trade_plan(symbol="BTCUSDT", timeframe="1h", side="BUY", entry=200, sl=180, close_time_ms=base_t)
    ev2 = _build_trade_plan(symbol="BTCUSDT", timeframe="4h", side="BUY", entry=200, sl=180, close_time_ms=base_t + 4 * 3600000)
    idem1 = ev1["payload"]["idempotency_key"]
    idem2 = ev2["payload"]["idempotency_key"]
    publish_event(r, "stream:trade_plan", ev1, event_type="trade_plan")
    time.sleep(0.5)
    publish_event(r, "stream:trade_plan", ev2, event_type="trade_plan")
    
    exited1 = _collect(
        "stream:execution_report",
        start_rep,
        lambda obj: (obj.get("payload") or {}).get("idempotency_key") == idem1
        and str((obj.get("payload") or {}).get("status") or "").upper() in ("EXITED", "POSITION_CLOSED", "PRIMARY_SL_HIT", "SECONDARY_SL_EXIT"),
        timeout_s=args.wait,
    )
    if not exited1:
        print_error("T2 å¤±è´¥: ä½æ—¶é—´æ¡†æ¶æŒä»“æœªè¢«å…³é—­")
        sys.exit(1)
    print_success("T2 é€šè¿‡: ä½æ—¶é—´æ¡†æ¶æŒä»“è¢«å…³é—­")
    
    filled2 = _collect(
        "stream:execution_report",
        start_rep,
        lambda obj: (obj.get("payload") or {}).get("idempotency_key") == idem2
        and str((obj.get("payload") or {}).get("status") or "").upper() in ("FILLED", "ORDER_SUBMITTED"),
        timeout_s=args.wait,
    )
    if not filled2:
        print_error("T2 å¤±è´¥: é«˜æ—¶é—´æ¡†æ¶è®¡åˆ’æœªæ‰§è¡Œ")
        sys.exit(1)
    print_success("T2 é€šè¿‡: é«˜æ—¶é—´æ¡†æ¶è®¡åˆ’æˆåŠŸæ‰§è¡Œ")
    
    # æµ‹è¯•3: cooldown
    print_info("[T3] æµ‹è¯•å†·å´æœŸåŠŸèƒ½ï¼ˆæ­¢æŸåé‡æ–°å…¥åœºåº”è¯¥è¢«é˜»æ­¢ï¼‰...")
    import psycopg
    with psycopg.connect(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("TRUNCATE TABLE orders, positions, cooldowns, execution_reports, risk_events, backtest_trades RESTART IDENTITY CASCADE;")
        conn.commit()
    time.sleep(1)
    
    start_rep = _xlast("stream:execution_report")
    start_risk = _xlast("stream:risk_event")
    base_t = now_ms()
    ev = _build_trade_plan(symbol="BTCUSDT", timeframe="1h", side="BUY", entry=100, sl=90, close_time_ms=base_t)
    idem = ev["payload"]["idempotency_key"]
    publish_event(r, "stream:trade_plan", ev, event_type="trade_plan")
    time.sleep(1)
    
    # å‘å¸ƒè§¦å‘æ­¢æŸçš„ bar_close
    bc = _build_bar_close(symbol="BTCUSDT", timeframe="1h", close_time_ms=base_t + 3600000, o=100, h=100, l=80, c=85)
    publish_event(r, "stream:bar_close", bc, event_type="bar_close")
    
    sl_rep = _collect(
        "stream:execution_report",
        start_rep,
        lambda obj: (obj.get("payload") or {}).get("idempotency_key") == idem
        and str((obj.get("payload") or {}).get("status") or "").upper() in ("PRIMARY_SL_HIT", "SECONDARY_SL_EXIT", "POSITION_CLOSED"),
        timeout_s=args.wait,
    )
    if not sl_rep:
        print_error("T3 å¤±è´¥: æœªç”Ÿæˆæ­¢æŸå¹³ä»“æŠ¥å‘Š")
        sys.exit(1)
    print_success("T3 é€šè¿‡: æ­¢æŸå¹³ä»“æŠ¥å‘Šå·²ç”Ÿæˆ")
    
    # å°è¯•åœ¨å†·å´æœŸå†…é‡æ–°å…¥åœº
    start_rep2 = _xlast("stream:execution_report")
    ev_re = _build_trade_plan(symbol="BTCUSDT", timeframe="1h", side="BUY", entry=100, sl=90, close_time_ms=base_t + 3600000)
    idem_re = ev_re["payload"]["idempotency_key"]
    publish_event(r, "stream:trade_plan", ev_re, event_type="trade_plan")
    
    reject_cd = _collect(
        "stream:execution_report",
        start_rep2,
        lambda obj: (obj.get("payload") or {}).get("idempotency_key") == idem_re
        and str((obj.get("payload") or {}).get("status") or "").upper() == "REJECTED",
        timeout_s=args.wait,
    )
    if not reject_cd:
        print_error("T3 å¤±è´¥: å†·å´æœŸå†…é‡æ–°å…¥åœºæœªè¢«æ‹’ç»")
        sys.exit(1)
    
    risk_cd = _collect(
        "stream:risk_event",
        start_risk,
        lambda obj: str((obj.get("payload") or {}).get("type") or "").upper() == "COOLDOWN_BLOCKED",
        timeout_s=args.wait,
    )
    if not risk_cd:
        print_error("T3 å¤±è´¥: æœªç”Ÿæˆ COOLDOWN_BLOCKED é£é™©äº‹ä»¶")
        sys.exit(1)
    print_success("T3 é€šè¿‡: å†·å´æœŸæˆåŠŸé˜»æ­¢é‡æ–°å…¥åœº")
    
    print()
    print_success("æ‰€æœ‰é£æ§é—¸é—¨æµ‹è¯•é€šè¿‡ï¼âœ…")

# ==================== å›æ”¾å›æµ‹åŠŸèƒ½ ====================

def cmd_replay(args):
    """å›æ”¾å›æµ‹å‘½ä»¤"""
    print("=" * 60)
    print("  å›æ”¾å›æµ‹")
    print("=" * 60)
    print()
    
    try:
        from libs.common.logging import setup_logging
        from libs.mq.redis_streams import RedisStreamsClient
        from libs.mq.events import publish_event
        from services.marketdata.publisher import build_bar_close_event
        from services.marketdata.repo_bars import upsert_bar
        from services.strategy.repo import get_bars, get_bars_range
        from libs.backtest.repo import insert_backtest_run, list_backtest_trades
        import hashlib
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    setup_logging("scripts/replay_backtest")
    
    symbol = args.symbol.upper()
    tf = args.timeframe
    
    def _gen_run_id(symbol: str, timeframe: str) -> str:
        seed = f"{symbol}|{timeframe}|{now_ms()}"
        return hashlib.sha256(seed.encode("utf-8")).hexdigest()[:16]
    
    def _fetch_and_upsert(symbol: str, interval: str, limit: int) -> None:
        """ä» Bybit REST æ‹‰å–æœ€è¿‘ N æ ¹ï¼ˆè¿‘ä¼¼ï¼‰å¹¶å†™åº“ã€‚"""
        from libs.bybit.market_rest import BybitMarketRestClient
        client = BybitMarketRestClient(base_url=settings.bybit_rest_base_url)
        bars = client.get_kline(symbol=symbol, interval=interval, limit=limit)
        bars = list(reversed(bars))
        for b in bars:
            start_ms = int(b["start_ms"])
            o = float(b["open"]); h = float(b["high"]); l = float(b["low"]); c = float(b["close"])
            v = float(b["volume"]); t = float(b.get("turnover")) if b.get("turnover") is not None else None
            if interval.isdigit():
                close_ms = start_ms + int(interval) * 60_000
            elif interval.upper() == "D":
                close_ms = start_ms + 24 * 60 * 60_000
            else:
                close_ms = start_ms
            upsert_bar(settings.database_url, symbol=symbol, timeframe=interval, open_time_ms=start_ms, close_time_ms=close_ms,
                       open=o, high=h, low=l, close=c, volume=v, turnover=t, source="REST")
    
    run_id = args.run_id or _gen_run_id(symbol, tf)
    
    if args.fetch:
        print_info(f"ä» Bybit REST æ‹‰å– {args.fetch_limit} æ ¹ K çº¿...")
        _fetch_and_upsert(symbol, tf, args.fetch_limit)
        print_success("K çº¿æ•°æ®å·²å†™å…¥æ•°æ®åº“")
    
    # é€‰æ‹© bars
    bars: List[Dict[str, Any]] = []
    if args.start_ms and args.end_ms:
        bars = get_bars_range(settings.database_url, symbol=symbol, timeframe=tf, start_close_time_ms=args.start_ms, end_close_time_ms=args.end_ms)
    else:
        lim = int(args.limit or 0)
        if lim <= 0:
            print_error("è¯·ä½¿ç”¨ --limit æˆ– --start-ms/--end-ms æŒ‡å®šå›æ”¾èŒƒå›´")
            sys.exit(1)
        bars = list(reversed(get_bars(settings.database_url, symbol=symbol, timeframe=tf, limit=lim)))
    
    if not bars:
        print_error("bars ä¸ºç©ºï¼šè¯·ç¡®è®¤ bars è¡¨å·²å†™å…¥æˆ–ä½¿ç”¨ --fetch")
        sys.exit(1)
    
    client = RedisStreamsClient(settings.redis_url)
    
    print_info(f"Run ID: {run_id}")
    print_info(f"Bars æ•°é‡: {len(bars)}")
    print_info(f"Symbol: {symbol}")
    print_info(f"Timeframe: {tf}")
    print()
    
    # å‘å¸ƒ bar_close
    print_info("å¼€å§‹å›æ”¾ bar_close äº‹ä»¶...")
    for i, b in enumerate(bars, start=1):
        evt = build_bar_close_event(
            symbol=symbol,
            timeframe=tf,
            close_time_ms=int(b["close_time_ms"]),
            source="REPLAY",
            ohlcv={
                "open": float(b["open"]),
                "high": float(b["high"]),
                "low": float(b["low"]),
                "close": float(b["close"]),
                "volume": float(b["volume"]),
            },
        )
        evt["payload"]["ext"] = {"run_id": run_id, "seq": i}
        publish_event(client, "stream:bar_close", evt, event_type="bar_close")
        if args.sleep_ms > 0:
            time.sleep(args.sleep_ms / 1000.0)
        
        if i % 100 == 0:
            print_info(f"å·²å›æ”¾ {i}/{len(bars)} æ ¹ K çº¿...")
    
    print_success(f"å·²å›æ”¾ {len(bars)} æ ¹ K çº¿")
    
    # ç”Ÿæˆå¹¶è½åº“ backtest_run
    try:
        trades = list_backtest_trades(settings.database_url, run_id=run_id)
        if trades:
            total = len(trades)
            win = sum(1 for t in trades if float(t.get("pnl_r") or 0.0) > 0)
            avg = sum(float(t.get("pnl_r") or 0.0) for t in trades) / max(total, 1)
            summary = {"trades": total, "win_rate": win / max(total, 1), "avg_pnl_r": avg}
        else:
            summary = {"trades": 0, "win_rate": 0.0, "avg_pnl_r": 0.0}
        
        insert_backtest_run(
            settings.database_url,
            run_id=run_id,
            name=f"REPLAY_{symbol}_{tf}",
            params={"mode": "REPLAY", "symbol": symbol, "timeframe": tf, "bars": len(bars)},
            summary=summary,
        )
        print_success(f"å›æµ‹è¿è¡Œè®°å½•å·²åˆ›å»º: run_id={run_id}")
    except Exception as e:
        print_warning(f"åˆ›å»ºå›æµ‹è¿è¡Œè®°å½•å¤±è´¥: {e}")
    
    print()
    print_success("å›æ”¾å›æµ‹å®Œæˆï¼")
    print_info(f"å»ºè®®ä½¿ç”¨ /v1/backtest-compare?run_id={run_id} æ£€æŸ¥é—­ç¯è¿›åº¦")

# ==================== é™æµå™¨è‡ªæµ‹åŠŸèƒ½ ====================

def cmd_ratelimit_test(args):
    """é™æµå™¨è‡ªæµ‹å‘½ä»¤"""
    print("=" * 60)
    print("  é™æµå™¨è‡ªæµ‹")
    print("=" * 60)
    print()
    
    try:
        from libs.bybit.ratelimit import EndpointGroup, get_rate_limiter
        import random
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    rl = get_rate_limiter(settings)
    
    symbols = ["BTCUSDT", "ETHUSDT", "BCHUSDT", "SOLUSDT", "XRPUSDT"]
    
    print_info("é™æµå™¨é…ç½®:")
    print(f"  max_wait_ms={rl.max_wait_ms}")
    print(f"  low_status_threshold={rl.low_status_threshold}")
    print()
    print_info("ç¯å¢ƒå˜é‡è¦†ç›–:")
    for k in [
        "BYBIT_PUBLIC_RPS",
        "BYBIT_PRIVATE_CRITICAL_RPS",
        "BYBIT_PRIVATE_ORDER_QUERY_RPS",
        "BYBIT_PRIVATE_ACCOUNT_QUERY_RPS",
        "BYBIT_PRIVATE_PER_SYMBOL_ORDER_QUERY_RPS",
        "BYBIT_PRIVATE_PER_SYMBOL_ACCOUNT_QUERY_RPS",
        "BYBIT_RATE_LIMIT_MAX_WAIT_MS",
    ]:
        val = getattr(settings, k.lower(), None)
        print(f"    {k}={val}")
    print()
    
    stats = {"crit_wait_ms": [], "order_query_wait_ms": [], "account_query_wait_ms": []}
    
    print_info("å¼€å§‹æ¨¡æ‹Ÿè¯·æ±‚ï¼ˆ200 æ¬¡ï¼‰...")
    start = time.time()
    for i in range(200):
        sym = random.choice(symbols)
        r = random.random()
        if r < 0.25:
            gw, sw = rl.acquire(group=EndpointGroup.PRIVATE_CRITICAL, symbol=sym)
            w = max(gw, sw)
            stats["crit_wait_ms"].append(w)
        elif r < 0.70:
            gw, sw = rl.acquire(group=EndpointGroup.PRIVATE_ORDER_QUERY, symbol=sym)
            w = max(gw, sw)
            stats["order_query_wait_ms"].append(w)
        else:
            gw, sw = rl.acquire(group=EndpointGroup.PRIVATE_ACCOUNT_QUERY, symbol=sym)
            w = max(gw, sw)
            stats["account_query_wait_ms"].append(w)
        
        if i % 50 == 0 and i > 0:
            time.sleep(0.4)
    
    elapsed = (time.time() - start) * 1000
    
    def p(xs, q):
        if not xs:
            return 0
        xs2 = sorted(xs)
        idx = int((len(xs2) - 1) * q)
        return xs2[idx]
    
    print()
    print_info("ç»“æœç»Ÿè®¡ï¼ˆæ¯«ç§’ï¼‰:")
    for k in ["crit_wait_ms", "order_query_wait_ms", "account_query_wait_ms"]:
        xs = stats[k]
        if xs:
            mean = sum(xs) / len(xs)
            print(f"  {k}:")
            print(f"    n={len(xs)}")
            print(f"    mean={mean:.1f}")
            print(f"    p50={p(xs, 0.50)}")
            print(f"    p90={p(xs, 0.90)}")
            print(f"    p99={p(xs, 0.99)}")
            print(f"    max={max(xs)}")
        else:
            print(f"  {k}: n=0")
    
    print()
    print_success(f"å®Œæˆï¼Œè€—æ—¶: {elapsed:.0f}ms")

# ==================== WebSocket å¤„ç†è‡ªæµ‹åŠŸèƒ½ ====================

def cmd_ws_test(args):
    """WebSocket å¤„ç†è‡ªæµ‹å‘½ä»¤"""
    print("=" * 60)
    print("  WebSocket å¤„ç†è‡ªæµ‹")
    print("=" * 60)
    print()
    
    try:
        import asyncio
        from services.execution.ws_private_ingest import handle_private_ws_message
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    SAMPLES = [
        {
            "topic": "order",
            "data": [{
                "symbol": "BCHUSDT",
                "orderId": "abc",
                "orderLinkId": "link_1",
                "orderStatus": "PartiallyFilled",
                "cumExecQty": "0.5",
                "avgPrice": "617.5"
            }]
        },
        {
            "topic": "execution",
            "data": [{
                "symbol": "BCHUSDT",
                "orderId": "abc",
                "orderLinkId": "link_1",
                "execId": "e1",
                "execQty": "0.5",
                "execPrice": "617.5",
                "cumExecQty": "0.5",
                "leavesQty": "0.71"
            }]
        },
        {
            "topic": "position",
            "data": [{
                "symbol": "BCHUSDT",
                "side": "Buy",
                "size": "1.21",
                "entryPrice": "617.5"
            }]
        },
        {
            "topic": "wallet",
            "data": [{
                "coin": [{"coin": "USDT", "walletBalance": "1000"}]
            }]
        }
    ]
    
    async def run_test():
        for i, m in enumerate(SAMPLES, start=1):
            topic = m.get('topic')
            print_info(f"æµ‹è¯•æ ·æœ¬ {i}: topic={topic}")
            try:
                await handle_private_ws_message(m)
                print_success(f"æ ·æœ¬ {i} å¤„ç†æˆåŠŸ")
            except Exception as e:
                print_error(f"æ ·æœ¬ {i} å¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            print()
    
    print_info("å¼€å§‹æµ‹è¯• WebSocket æ¶ˆæ¯å¤„ç†...")
    print()
    asyncio.run(run_test())
    print_success("WebSocket å¤„ç†è‡ªæµ‹å®Œæˆï¼")

# ==================== æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥åŠŸèƒ½ ====================

def cmd_db_check():
    """æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å‘½ä»¤"""
    print("=" * 60)
    print("  æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    print("[1] æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
    try:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT 1")
            print_success("æ•°æ®åº“è¿æ¥æ­£å¸¸")
    except Exception as e:
        print_error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    print()
    
    # æ£€æŸ¥å¿…è¦çš„è¡¨
    print("[2] æ£€æŸ¥å¿…è¦çš„è¡¨...")
    REQUIRED_TABLES = [
        "bars", "signals", "trade_plans", "orders", "positions",
        "execution_reports", "risk_events", "risk_state",
        "setups", "triggers", "pivots", "indicator_snapshots",
        "notifications", "execution_traces", "account_snapshots",
        "cooldowns", "ws_events", "backtest_runs", "backtest_trades",
        "app_migrations",
    ]
    
    missing_tables = []
    with get_conn(settings.database_url) as conn:
        for table in REQUIRED_TABLES:
            with conn.cursor() as cur:
                cur.execute(
                    "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = %s)",
                    (table,),
                )
                exists = cur.fetchone()[0]
                if exists:
                    print(f"   âœ… è¡¨ {table} å­˜åœ¨")
                else:
                    print(f"   âŒ è¡¨ {table} ä¸å­˜åœ¨")
                    missing_tables.append(table)
    
    if missing_tables:
        print()
        print_warning(f"ç¼ºå°‘ {len(missing_tables)} ä¸ªè¡¨: {', '.join(missing_tables)}")
        print_info("å»ºè®®è¿è¡Œ: python -m scripts.trading_test_tool init-db")
    else:
        print()
        print_success("æ‰€æœ‰å¿…è¦çš„è¡¨éƒ½å­˜åœ¨")
    
    print()
    
    # æ£€æŸ¥å…³é”®è¡¨çš„ç»“æ„
    print("[3] æ£€æŸ¥å…³é”®è¡¨çš„ç»“æ„...")
    KEY_TABLES = {
        "orders": ["order_id", "idempotency_key", "symbol", "side", "order_type", "qty", "status", "bybit_order_id"],
        "positions": ["position_id", "idempotency_key", "symbol", "side", "qty_total", "status"],
        "trade_plans": ["plan_id", "idempotency_key", "symbol", "side", "entry_price", "primary_sl_price"],
        "execution_reports": ["report_id", "plan_id", "symbol", "type", "status"],
    }
    
    with get_conn(settings.database_url) as conn:
        for table, columns in KEY_TABLES.items():
            with conn.cursor() as cur:
                cur.execute(
                    "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = %s)",
                    (table,),
                )
                if not cur.fetchone()[0]:
                    print_warning(f"è¡¨ {table} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç»“æ„æ£€æŸ¥")
                    continue
            
            print(f"   æ£€æŸ¥è¡¨ {table}...")
            missing_cols = []
            for col in columns:
                with conn.cursor() as cur:
                    cur.execute(
                        "SELECT EXISTS (SELECT FROM information_schema.columns WHERE table_name = %s AND column_name = %s)",
                        (table, col),
                    )
                    if cur.fetchone()[0]:
                        print(f"     âœ… åˆ— {col} å­˜åœ¨")
                    else:
                        print(f"     âŒ åˆ— {col} ä¸å­˜åœ¨")
                        missing_cols.append(col)
            
            if missing_cols:
                print_warning(f"è¡¨ {table} ç¼ºå°‘åˆ—: {', '.join(missing_cols)}")
    
    print()
    
    # æ£€æŸ¥è¿ç§»ç‰ˆæœ¬
    print("[4] æ£€æŸ¥æ•°æ®åº“è¿ç§»ç‰ˆæœ¬...")
    with get_conn(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'app_migrations')")
            if not cur.fetchone()[0]:
                print_warning("è¿ç§»è¡¨ä¸å­˜åœ¨ï¼Œå¯èƒ½æœªè¿è¡Œè¿ç§»")
                print_info("å»ºè®®è¿è¡Œ: python -m scripts.trading_test_tool init-db")
            else:
                cur.execute("SELECT filename, applied_at FROM app_migrations ORDER BY applied_at DESC")
                migrations = cur.fetchall()
                print_success(f"å·²åº”ç”¨ {len(migrations)} ä¸ªè¿ç§»")
                print()
                print("   æœ€è¿‘çš„è¿ç§»ï¼š")
                for filename, applied_at in migrations[:10]:
                    print(f"     - {filename} ({applied_at})")
                
                # æ£€æŸ¥è¿ç§»æ–‡ä»¶æ•°é‡
                migrations_dir = project_root / "migrations" / "postgres"
                migration_files = sorted(migrations_dir.glob("V*.sql"))
                if len(migration_files) > len(migrations):
                    print()
                    print_warning(f"è¿ç§»æ–‡ä»¶æ•°é‡ ({len(migration_files)}) å¤§äºå·²åº”ç”¨æ•°é‡ ({len(migrations)})")
                    print_info("å»ºè®®è¿è¡Œ: python -m scripts.trading_test_tool init-db")
    
    print()
    
    # æ£€æŸ¥æ•°æ®ç»Ÿè®¡
    print("[5] æ£€æŸ¥æ•°æ®ç»Ÿè®¡...")
    STAT_TABLES = ["bars", "signals", "trade_plans", "orders", "positions", "execution_reports", "risk_events"]
    
    with get_conn(settings.database_url) as conn:
        print("   è¡¨è®°å½•æ•°ï¼š")
        for table in STAT_TABLES:
            with conn.cursor() as cur:
                cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = %s)", (table,))
                if not cur.fetchone()[0]:
                    print(f"     {table}: è¡¨ä¸å­˜åœ¨")
                    continue
                try:
                    cur.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cur.fetchone()[0]
                    print(f"     {table}: {count} æ¡è®°å½•")
                except Exception:
                    print(f"     {table}: æŸ¥è¯¢å¤±è´¥")
    
    print()
    
    # æ£€æŸ¥ OPEN æŒä»“
    print("[6] æ£€æŸ¥ OPEN æŒä»“...")
    with get_conn(settings.database_url) as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'positions')")
            if cur.fetchone()[0]:
                cur.execute("SELECT COUNT(*) FROM positions WHERE status='OPEN'")
                open_count = cur.fetchone()[0]
                
                if open_count == 0:
                    print_success("æ²¡æœ‰ OPEN æŒä»“")
                else:
                    print_warning(f"æœ‰ {open_count} ä¸ª OPEN æŒä»“")
                    cur.execute(
                        "SELECT position_id, symbol, side, qty_total, created_at FROM positions WHERE status='OPEN' ORDER BY created_at DESC LIMIT 5"
                    )
                    print("   æŒä»“åˆ—è¡¨ï¼š")
                    for row in cur.fetchall():
                        print(f"     - {row[1]} {row[2]} qty={row[3]} (id={row[0][:20]}...)")
            else:
                print_warning("positions è¡¨ä¸å­˜åœ¨")
    
    print()
    print("=" * 60)
    print("  æ£€æŸ¥æ€»ç»“")
    print("=" * 60)
    print()
    
    if missing_tables:
        print_error("æ•°æ®åº“ä¸å®Œæ•´ï¼šç¼ºå°‘ä»¥ä¸‹è¡¨")
        for table in missing_tables:
            print(f"   - {table}")
        print()
        print_info("ä¿®å¤å»ºè®®ï¼š")
        print("   è¿è¡Œæ•°æ®åº“è¿ç§»ï¼š")
        print("     python -m scripts.trading_test_tool init-db")
        print("   æˆ–åœ¨ Docker å®¹å™¨ä¸­ï¼š")
        print("     docker compose exec execution python -m scripts.trading_test_tool init-db")
        sys.exit(1)
    else:
        print_success("æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        print()
        print("æ‰€æœ‰å¿…è¦çš„è¡¨éƒ½å­˜åœ¨ï¼Œæ•°æ®åº“ç»“æ„å®Œæ•´ã€‚")

# ==================== ç¦»çº¿å›æµ‹åŠŸèƒ½ ====================

def cmd_backtest(args):
    """ç¦»çº¿å›æµ‹å‘½ä»¤"""
    print("=" * 60)
    print("  ç¦»çº¿å›æµ‹")
    print("=" * 60)
    print()
    
    try:
        import hashlib
        from services.strategy.repo import get_bars
        from libs.backtest.engine import backtest
        from libs.backtest.report import summarize, to_jsonable
        from libs.backtest.repo import insert_backtest_run, insert_backtest_trade
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    symbol = args.symbol.upper()
    tf = args.timeframe
    
    print_info(f"Symbol: {symbol}, Timeframe: {tf}, Limit: {args.limit}")
    
    bars = get_bars(settings.database_url, symbol=symbol, timeframe=tf, limit=args.limit)
    if len(bars) < 200:
        print_error(f"bars æ•°é‡å¤ªå°‘: {len(bars)}ï¼Œè‡³å°‘éœ€è¦ 200 æ ¹")
        sys.exit(1)
    
    print_info(f"è·å–åˆ° {len(bars)} æ ¹ K çº¿")
    
    results = backtest(
        symbol=symbol,
        timeframe=tf,
        bars=bars,
        min_confirmations=settings.min_confirmations,
        trail_mode=args.trail,
        atr_period=args.atr_period,
        atr_mult=args.atr_mult,
    )
    
    summary = summarize(results)
    print()
    print("å›æµ‹ç»“æœæ±‡æ€»ï¼š")
    print(json.dumps(summary, ensure_ascii=False, indent=2))
    
    # ä¿å­˜æŠ¥å‘Š
    Path("reports").mkdir(exist_ok=True)
    ts = int(time.time())
    path = Path("reports") / f"backtest_{symbol}_{tf}_{ts}.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump({"summary": summary, "results": to_jsonable(results)}, f, ensure_ascii=False, indent=2)
    print()
    print_success(f"æŠ¥å‘Šå·²ä¿å­˜: {path}")
    
    # å¯é€‰å†™å…¥æ•°æ®åº“
    if args.write_db:
        run_id = args.run_id.strip() or hashlib.sha256(f"{symbol}|{tf}|{ts}".encode("utf-8")).hexdigest()
        start_ms = int(bars[0].get("open_time_ms") or bars[0].get("ts_ms") or 0)
        end_ms = int(bars[-1].get("close_time_ms") or bars[-1].get("ts_ms") or 0)
        params = {
            "trail": args.trail,
            "atr_period": args.atr_period,
            "atr_mult": args.atr_mult,
            "limit": args.limit,
        }
        insert_backtest_run(
            settings.database_url,
            run_id=run_id,
            symbol=symbol,
            timeframe=tf,
            start_time_ms=start_ms,
            end_time_ms=end_ms,
            params=params,
            summary=summary,
        )
        # é€ç¬”äº¤æ˜“è½åº“
        js = to_jsonable(results)
        for idx, tr in enumerate(js):
            trade_id = hashlib.sha256(f"{run_id}|{idx}".encode("utf-8")).hexdigest()
            entry_i = int(tr.get("entry_i", 0))
            exit_i = int(tr.get("exit_i", 0))
            entry_time_ms = int((bars[entry_i].get("close_time_ms") if entry_i < len(bars) else 0) or 0)
            exit_time_ms = int((bars[exit_i].get("close_time_ms") if exit_i < len(bars) else 0) or 0)
            side = tr.get("side")
            side2 = "LONG" if side == "BUY" else ("SHORT" if side == "SELL" else str(side))
            insert_backtest_trade(
                settings.database_url,
                trade_id=trade_id,
                run_id=run_id,
                symbol=symbol,
                timeframe=tf,
                entry_time_ms=entry_time_ms,
                exit_time_ms=exit_time_ms,
                side=side2,
                entry_price=float(tr.get("entry")),
                exit_price=float(tr.get("legs", [])[-1].get("price")) if tr.get("legs") else float(tr.get("entry")),
                pnl_r=float(tr.get("pnl_r")),
                reason=str(tr.get("reason")),
                legs=tr.get("legs", []),
            )
        print_success(f"å›æµ‹ç»“æœå·²å†™å…¥æ•°æ®åº“: run_id={run_id}")

# ==================== å›æ”¾+æŠ¥å‘ŠåŠŸèƒ½ ====================

def cmd_replay_report(args):
    """å›æ”¾+ç­‰å¾…+æŠ¥å‘Šç”Ÿæˆå‘½ä»¤"""
    print("=" * 60)
    print("  å›æ”¾å›æµ‹ + æŠ¥å‘Šç”Ÿæˆ")
    print("=" * 60)
    print()
    
    try:
        import httpx
        from libs.mq.redis_streams import RedisStreamsClient
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    STREAMS = [
        "stream:bar_close",
        "stream:signal",
        "stream:trade_plan",
        "stream:execution_report",
        "stream:risk_event",
        "stream:dlq",
    ]
    
    # ç¡®ä¿ streams/groups
    c = RedisStreamsClient(settings.redis_url)
    for s in STREAMS:
        c.ensure_group(s, settings.redis_stream_group)
    
    # æ‰§è¡Œå›æ”¾ï¼ˆå¤ç”¨ replay å‘½ä»¤çš„é€»è¾‘ï¼‰
    print_info("æ‰§è¡Œå›æ”¾...")
    replay_args = argparse.Namespace(
        symbol=args.symbol,
        timeframe=args.timeframe,
        limit=args.limit,
        run_id=args.run_id,
        start_ms=None,
        end_ms=None,
        fetch=False,
        fetch_limit=0,
        sleep_ms=0,
    )
    cmd_replay(replay_args)
    
    # è·å– run_idï¼ˆä»å›æ”¾å‘½ä»¤çš„è¾“å‡ºæˆ–å‚æ•°ï¼‰
    run_id = args.run_id.strip() if args.run_id else ""
    if not run_id:
        # ä» Redis æœ€æœ«ä¸€æ¡ bar_close è¯»å– ext.run_id
        try:
            last = c.r.xrevrange("stream:bar_close", count=1)
            if last:
                _mid, fields = last[0]
                evt = json.loads(fields.get("json")) if "json" in fields else fields
                run_id = ((evt.get("payload") or {}).get("ext") or {}).get("run_id") or ""
        except Exception:
            pass
    
    if not run_id:
        print_error("æ— æ³•è·å– run_idï¼šå»ºè®®æ˜¾å¼ä¼  --run-id")
        sys.exit(1)
    
    print_info(f"Run ID: {run_id}")
    print()
    
    # ç­‰å¾…é“¾è·¯å¤„ç†å®Œæˆ
    print_info("ç­‰å¾…é“¾è·¯å¤„ç†å®Œæˆ...")
    timeout_sec = args.timeout_sec
    stable_sec = 5
    
    def _db_count_positions(run_id: str, status: str) -> int:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT COUNT(1) FROM positions WHERE (meta->>'run_id')=%s AND status=%s", (run_id, status))
                row = cur.fetchone()
                return int(row[0]) if row else 0
    
    start = time.time()
    stable_start: Optional[float] = None
    
    while True:
        pend = {s: c.pending_count(s, settings.redis_stream_group) for s in STREAMS}
        open_pos = _db_count_positions(run_id, "OPEN")
        
        all_zero = all(int(v) == 0 for v in pend.values())
        done = all_zero and open_pos == 0
        
        if done:
            if stable_start is None:
                stable_start = time.time()
            if (time.time() - stable_start) >= stable_sec:
                wait_result = {"pending": pend, "positions_open": open_pos, "wait_sec": int(time.time() - start)}
                break
        else:
            stable_start = None
        
        if (time.time() - start) > timeout_sec:
            wait_result = {"pending": pend, "positions_open": open_pos, "wait_sec": int(time.time() - start), "timeout": True}
            break
        
        time.sleep(1.0)
    
    print_success(f"ç­‰å¾…å®Œæˆï¼Œè€—æ—¶ {wait_result.get('wait_sec')} ç§’")
    print()
    
    # ç»Ÿè®¡
    def _db_count_jsonb_run_id(table: str, run_id: str) -> int:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute(f"SELECT COUNT(1) FROM {table} WHERE (payload->'payload'->'ext'->>'run_id') = %s", (run_id,))
                row = cur.fetchone()
                return int(row[0]) if row else 0
    
    def _db_count_orders_run_id(run_id: str) -> int:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT COUNT(1) FROM orders WHERE (payload->'ext'->>'run_id')=%s", (run_id,))
                row = cur.fetchone()
                return int(row[0]) if row else 0
    
    def _db_list_backtest_trades(run_id: str, limit: int = 200) -> List[Dict[str, Any]]:
        with get_conn(settings.database_url) as conn:
            with conn.cursor() as cur:
                cur.execute(
                    "SELECT trade_id, run_id, symbol, timeframe, entry_time_ms, exit_time_ms, side, entry_price, exit_price, pnl_r, reason, legs "
                    "FROM backtest_trades WHERE run_id=%s ORDER BY entry_time_ms ASC LIMIT %s",
                    (run_id, limit),
                )
                cols = [d.name for d in cur.description]
                out = []
                for row in cur.fetchall():
                    out.append({cols[i]: row[i] for i in range(len(cols))})
                return out
    
    stats = {
        "signals": _db_count_jsonb_run_id("signals", run_id),
        "trade_plans": _db_count_jsonb_run_id("trade_plans", run_id),
        "orders": _db_count_orders_run_id(run_id),
        "execution_reports": _db_count_jsonb_run_id("execution_reports", run_id),
        "positions_open": _db_count_positions(run_id, "OPEN"),
        "positions_closed": _db_count_positions(run_id, "CLOSED"),
        "backtest_trades": len(_db_list_backtest_trades(run_id, limit=100000)),
    }
    trades = _db_list_backtest_trades(run_id, limit=200)
    
    # ç”ŸæˆæŠ¥å‘Š
    Path("reports").mkdir(exist_ok=True)
    out_json = Path("reports") / f"replay_{run_id}.json"
    out_md = Path("reports") / f"replay_{run_id}.md"
    
    blob = {"run_id": run_id, "stats": stats, "wait": wait_result, "trades": trades}
    
    # API compareï¼ˆå¯é€‰ï¼‰
    api_compare = None
    if args.api_url.strip():
        try:
            api_compare = httpx.get(
                f"{args.api_url.rstrip('/')}/v1/backtest-compare",
                params={"run_id": run_id, "limit_trades": 50},
                timeout=10.0,
            ).json()
            blob["api_compare"] = api_compare
        except Exception:
            pass
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    lines: List[str] = []
    lines.append(f"# trading-ci å›æ”¾æŠ¥å‘Š")
    lines.append("")
    lines.append(f"- run_id: `{run_id}`")
    lines.append(f"- symbol: `{args.symbol}`  timeframe: `{args.timeframe}`  limit: `{args.limit}`")
    lines.append(f"- mode(EXECUTION_MODE): `{settings.execution_mode}`")
    lines.append("")
    lines.append("## ç­‰å¾…é“¾è·¯ç©ºé—²ç»“æœ")
    lines.append(f"- wait_sec: {wait_result.get('wait_sec')}  timeout: {bool(wait_result.get('timeout', False))}")
    lines.append(f"- positions_open: {wait_result.get('positions_open')} ")
    lines.append("- pending:")
    for k, v in (wait_result.get("pending") or {}).items():
        lines.append(f"  - {k}: {v}")
    lines.append("")
    lines.append("## äº§ç‰©ç»Ÿè®¡ï¼ˆæŒ‰ run_id è¿‡æ»¤ï¼‰")
    for k, v in stats.items():
        lines.append(f"- {k}: {v}")
    lines.append("")
    lines.append("## backtest_tradesï¼ˆå‰ 50 æ¡ï¼‰")
    if not trades:
        lines.append("- ï¼ˆç©ºï¼‰")
    else:
        lines.append("| idx | side | pnl_r | entry_time_ms | exit_time_ms | reason | idempotency_key | trade_id |")
        lines.append("|---:|---|---:|---:|---:|---|---|---|")
        for i, tr in enumerate(trades[:50], start=1):
            legs = tr.get("legs") or []
            idem = ""
            if isinstance(legs, list) and legs:
                idem = str(legs[0].get("idempotency_key", "")) if isinstance(legs[0], dict) else ""
            lines.append(f"| {i} | {tr.get('side')} | {tr.get('pnl_r')} | {tr.get('entry_time_ms')} | {tr.get('exit_time_ms')} | {tr.get('reason')} | {idem} | {tr.get('trade_id')} |")
    
    if api_compare is not None:
        lines.append("")
        lines.append("## API /v1/backtest-compare è¿”å›ï¼ˆå¯é€‰ï¼‰")
        lines.append("```json")
        lines.append(json.dumps(api_compare, ensure_ascii=False, indent=2))
        lines.append("```")
    
    out_json.write_text(json.dumps(blob, ensure_ascii=False, indent=2), encoding="utf-8")
    out_md.write_text("\n".join(lines) + "\n", encoding="utf-8")
    
    print_success(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {out_md}, {out_json}")

# ==================== å†å²ä¿¡å·åˆ†æåŠŸèƒ½ ====================

def cmd_analyze_signals(args):
    """å†å²ä¿¡å·åˆ†æå‘½ä»¤ï¼šåˆ†æè¿‡å»æŒ‡å®šå¹´æ•°çš„ç­–ç•¥ä¿¡å·å‡ºç°æ¬¡æ•°"""
    print("=" * 60)
    print("  å†å²ä¿¡å·åˆ†æ")
    print("=" * 60)
    print()
    
    try:
        from datetime import datetime, timedelta
        from libs.strategy.divergence import detect_three_segment_divergence
        from libs.strategy.confluence import Candle, vegas_state, engulfing, rsi_divergence, obv_divergence, fvg_proximity
        from services.strategy.repo import get_bars_range
        from services.marketdata.repo_bars import upsert_bar
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    symbol = args.symbol.upper()
    tf = args.timeframe
    
    # ç­–ç•¥ç±»å‹å¤„ç†
    strategy_filter = args.strategy.strip().upper() if args.strategy else None
    strategy_filter_confirmations = None
    
    if strategy_filter:
        if strategy_filter == "ALL":
            strategy_filter = None  # None è¡¨ç¤ºä¸ç­›é€‰
        elif strategy_filter != "MACD_3SEG_DIVERGENCE":
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¡®è®¤é¡¹ç»„åˆï¼ˆå¦‚ "ENGULFING+RSI_DIV"ï¼‰
            valid_confirmations = {"ENGULFING", "RSI_DIV", "OBV_DIV", "FVG_PROXIMITY"}
            parts = strategy_filter.split("+")
            if all(p in valid_confirmations for p in parts):
                strategy_filter_confirmations = set(parts)
            else:
                print_warning(f"æœªè¯†åˆ«çš„ç­–ç•¥ç±»å‹æˆ–ç¡®è®¤é¡¹ç»„åˆ: {strategy_filter}")
                print_info("æ”¯æŒçš„ç­–ç•¥ç±»å‹:")
                print("  - ALL: åˆ†ææ‰€æœ‰ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰")
                print("  - MACD_3SEG_DIVERGENCE: MACD ä¸‰æ®µèƒŒç¦»ç­–ç•¥")
                print("  - ç¡®è®¤é¡¹ç»„åˆï¼ˆå¦‚ ENGULFING+RSI_DIVï¼‰: æŒ‰ç¡®è®¤é¡¹ç»„åˆç­›é€‰")
                print("    æ”¯æŒçš„ç¡®è®¤é¡¹: ENGULFING, RSI_DIV, OBV_DIV, FVG_PROXIMITY")
                print()
    
    strategy_name_display = (strategy_filter if strategy_filter else "ALLï¼ˆæ‰€æœ‰ç­–ç•¥ï¼‰")
    print_info(f"ç­–ç•¥ç­›é€‰: {strategy_name_display}")
    
    # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæ”¯æŒå¤šç§æ–¹å¼ï¼‰
    # ä¼˜å…ˆçº§ï¼šstart-date + end-date > months/days/yearsï¼ˆä»å½“å‰æ—¶é—´å¾€å‰æ¨ï¼‰
    try:
        # æ£€æŸ¥å‚æ•°äº’æ–¥æ€§
        time_range_params = [args.years != 3, args.months is not None, args.days is not None, args.start_date is not None]
        if sum(time_range_params) > 1:
            print_error("æ—¶é—´èŒƒå›´å‚æ•°äº’æ–¥ï¼Œè¯·åªæŒ‡å®šä¸€ç§ï¼š--yearsã€--monthsã€--days æˆ– --start-date")
            print_info("ç¤ºä¾‹ï¼š")
            print("  --years 1     # è¿‡å»1å¹´")
            print("  --months 12   # è¿‡å»12ä¸ªæœˆ")
            print("  --days 365    # è¿‡å»365å¤©")
            print("  --start-date 2023-01-01 --end-date 2023-12-31  # ç²¾ç¡®æ—¥æœŸèŒƒå›´")
            sys.exit(1)
        
        if args.start_date:
            # è§£æå¼€å§‹æ—¥æœŸ
            start_date_str = args.start_date.strip()
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            date_formats = [
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d",
                "%Y/%m/%d %H:%M:%S",
                "%Y/%m/%d",
            ]
            start_time = None
            for fmt in date_formats:
                try:
                    start_time = datetime.strptime(start_date_str, fmt)
                    break
                except ValueError:
                    continue
            
            if start_time is None:
                print_error(f"æ— æ³•è§£æå¼€å§‹æ—¥æœŸ: {args.start_date}")
                print_info("æ”¯æŒçš„æ—¥æœŸæ ¼å¼: YYYY-MM-DD æˆ– YYYY-MM-DD HH:MM:SS")
                sys.exit(1)
            
            # è§£æç»“æŸæ—¥æœŸï¼ˆç²¾ç¡®æ—¥æœŸèŒƒå›´æ¨¡å¼ï¼‰
            if args.end_date:
                # ä½¿ç”¨ç»“æŸæ—¥æœŸ
                end_date_str = args.end_date.strip()
                end_time = None
                for fmt in date_formats:
                    try:
                        end_time = datetime.strptime(end_date_str, fmt)
                        break
                    except ValueError:
                        continue
                
                if end_time is None:
                    print_error(f"æ— æ³•è§£æç»“æŸæ—¥æœŸ: {args.end_date}")
                    print_info("æ”¯æŒçš„æ—¥æœŸæ ¼å¼: YYYY-MM-DD æˆ– YYYY-MM-DD HH:MM:SS")
                    sys.exit(1)
                
                years = (end_time - start_time).days / 365.0  # ç”¨äºæ˜¾ç¤º
            else:
                # æœªæŒ‡å®šç»“æŸæ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                end_time = datetime.now()
                years = (end_time - start_time).days / 365.0  # ç”¨äºæ˜¾ç¤º
        elif args.months:
            # ä½¿ç”¨æœˆæ•°æ–¹å¼ï¼ˆä»å½“å‰æ—¶é—´å¾€å‰æ¨ï¼‰
            end_time = datetime.now()
            start_time = end_time - timedelta(days=args.months * 30)  # è¿‘ä¼¼ï¼šæ¯æœˆ30å¤©
            years = args.months / 12.0  # ç”¨äºæ˜¾ç¤º
        elif args.days:
            # ä½¿ç”¨å¤©æ•°æ–¹å¼ï¼ˆä»å½“å‰æ—¶é—´å¾€å‰æ¨ï¼‰
            end_time = datetime.now()
            start_time = end_time - timedelta(days=args.days)
            years = args.days / 365.0  # ç”¨äºæ˜¾ç¤º
        else:
            # ä½¿ç”¨å¹´æ•°æ–¹å¼ï¼ˆé»˜è®¤ï¼Œä»å½“å‰æ—¶é—´å¾€å‰æ¨ï¼‰
            years = args.years
            end_time = datetime.now()
            start_time = end_time - timedelta(days=years * 365)
    except Exception as e:
        print_error(f"æ—¥æœŸè§£æé”™è¯¯: {e}")
        sys.exit(1)
    
    # ç¡®ä¿å¼€å§‹æ—¶é—´ < ç»“æŸæ—¶é—´
    if start_time >= end_time:
        print_error(f"å¼€å§‹æ—¶é—´å¿…é¡»æ—©äºç»“æŸæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} >= {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        sys.exit(1)
    
    start_ms = int(start_time.timestamp() * 1000)
    end_ms = int(end_time.timestamp() * 1000)
    
    print_info(f"Symbol: {symbol}")
    print_info(f"Timeframe: {tf}")
    time_range_desc = f"{start_time.strftime('%Y-%m-%d %H:%M:%S')} è‡³ {end_time.strftime('%Y-%m-%d %H:%M:%S')}"
    
    # æ ¹æ®å‚æ•°ç±»å‹æ˜¾ç¤ºä¸åŒçš„æè¿°
    if args.start_date:
        days_span = (end_time - start_time).days
        time_range_desc += f" (ç²¾ç¡®æ—¥æœŸèŒƒå›´: å…± {days_span} å¤©)"
    elif args.months:
        time_range_desc += f" (è¿‡å» {args.months} ä¸ªæœˆ)"
    elif args.days:
        time_range_desc += f" (è¿‡å» {args.days} å¤©)"
    else:
        time_range_desc += f" (è¿‡å» {years} å¹´)"
    
    print_info(f"æ—¶é—´èŒƒå›´: {time_range_desc}")
    print()
    
    # 1. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» Bybit API è·å–
    print_info("æ£€æŸ¥æ•°æ®åº“ä¸­çš„å†å²æ•°æ®...")
    bars = get_bars_range(settings.database_url, symbol=symbol, timeframe=tf, start_close_time_ms=start_ms, end_close_time_ms=end_ms)
    
    # è®¡ç®—éœ€è¦çš„ bar æ•°é‡ï¼ˆä¼°ç®—ï¼‰
    tf_ms = timeframe_ms(tf)
    estimated_bars = int((end_ms - start_ms) / tf_ms) + 100  # åŠ ä¸€äº›ä½™é‡
    
    if len(bars) < estimated_bars * 0.8:  # å¦‚æœç¼ºå°‘è¶…è¿‡20%çš„æ•°æ®ï¼Œè‡ªåŠ¨ä» API è·å–
        missing_pct = (1 - len(bars) / estimated_bars) * 100
        print_warning(f"æ•°æ®åº“ä¸­çš„æ•°æ®ä¸å®Œæ•´: æ‰¾åˆ° {len(bars)} æ ¹ï¼Œé¢„è®¡éœ€è¦çº¦ {estimated_bars} æ ¹ï¼ˆç¼ºå¤±çº¦ {missing_pct:.1f}%ï¼‰")
        
        # è‡ªåŠ¨ä¿®å¤ï¼šæ•°æ®ç¼ºå¤±è¶…è¿‡20%æ—¶ï¼Œè‡ªåŠ¨ä» API è·å–
        print_info("æ£€æµ‹åˆ°æ•°æ®ä¸å®Œæ•´ï¼Œè‡ªåŠ¨ä» Bybit API è·å–å†å²æ•°æ®...")
        interval = bybit_interval_for_system_timeframe(tf)
        if not interval:
            print_error(f"ä¸æ”¯æŒçš„ timeframe: {tf}ï¼ˆæ— æ³•æ˜ å°„åˆ° Bybit intervalï¼‰")
            sys.exit(1)
        
        rest = BybitMarketRestClient(settings.bybit_base_url)
        
        # åˆ†æ‰¹è·å–ï¼ˆBybit API é™åˆ¶æ¯æ¬¡æœ€å¤š 1000 æ ¹ï¼‰
        all_candles = []
        cursor = start_ms
        batch_count = 0
        max_batches = 200  # å®‰å…¨é™åˆ¶
        
        print_info(f"å¼€å§‹ä» Bybit API è·å–å†å²æ•°æ®...")
        print_info(f"  æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(start_ms/1000).strftime('%Y-%m-%d %H:%M:%S')} è‡³ {datetime.fromtimestamp(end_ms/1000).strftime('%Y-%m-%d %H:%M:%S')}")
        print_info(f"  åˆå§‹æ¸¸æ ‡: {datetime.fromtimestamp(cursor/1000).strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        while cursor < end_ms and batch_count < max_batches:
            batch_count += 1
            try:
                print(f"  è¯·æ±‚æ‰¹æ¬¡ {batch_count}: start_ms={datetime.fromtimestamp(cursor/1000).strftime('%Y-%m-%d %H:%M:%S')}, end_ms={datetime.fromtimestamp(end_ms/1000).strftime('%Y-%m-%d %H:%M:%S')}")
                candles = rest.get_kline(
                    symbol=symbol,
                    interval=interval,
                    category="linear",
                    start_ms=cursor,
                    end_ms=end_ms,
                    limit=1000,
                )
                if not candles:
                    print_warning(f"æ‰¹æ¬¡ {batch_count}ï¼šAPI è¿”å›ç©ºæ•°æ®")
                    break
                
                # Bybit API è¿”å›çš„æ˜¯é€†åºï¼ˆä»æ–°åˆ°æ—§ï¼‰ï¼Œéœ€è¦åè½¬ä¸ºæ­£åº
                # reversed åï¼šcandles[0] æ˜¯æœ€æ—§çš„ï¼Œcandles[-1] æ˜¯æœ€æ–°çš„
                candles = list(reversed(candles))
                
                if not candles:
                    break
                
                # æ‰¾åˆ°æœ¬æ‰¹æ¬¡ä¸­æœ€æ—§å’Œæœ€æ–°çš„æ—¶é—´æˆ³ï¼ˆç”¨äºè°ƒè¯•å’Œæ¨è¿›æ¸¸æ ‡ï¼‰
                batch_valid_candles = []
                min_start_ms = None
                max_start_ms = None
                
                # å‚è€ƒ _rest_backfill_range çš„é€»è¾‘ï¼šéå†æ‰€æœ‰ candlesï¼Œåªä¿å­˜æ—¶é—´èŒƒå›´å†…çš„
                for c in candles:
                    c_start_ms = int(c["start_ms"])
                    # åªå¤„ç†æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
                    if c_start_ms < start_ms or c_start_ms > end_ms:
                        continue
                    
                    batch_valid_candles.append(c)
                    if min_start_ms is None or c_start_ms < min_start_ms:
                        min_start_ms = c_start_ms
                    if max_start_ms is None or c_start_ms > max_start_ms:
                        max_start_ms = c_start_ms
                
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¯´æ˜å·²è¶…å‡ºèŒƒå›´
                if not batch_valid_candles:
                    print_warning(f"æ‰¹æ¬¡ {batch_count}ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®åœ¨æ—¶é—´èŒƒå›´å†…ï¼Œå¯èƒ½å·²è·å–å®Œ")
                    break
                
                if min_start_ms is None or max_start_ms is None:
                    break
                
                # ä¿å­˜æœ‰æ•ˆæ•°æ®åˆ°æ•°æ®åº“
                batch_new_count = 0
                for c in batch_valid_candles:
                    c_start_ms = int(c["start_ms"])
                    
                    # è®¡ç®— close_time_ms
                    if interval.isdigit():
                        c_close_ms = c_start_ms + int(interval) * 60 * 1000 - 1
                    else:
                        c_close_ms = c_start_ms
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    upsert_bar(
                        settings.database_url,
                        symbol=symbol,
                        timeframe=tf,
                        open_time_ms=c_start_ms,
                        close_time_ms=c_close_ms,
                        open=float(c["open"]),
                        high=float(c["high"]),
                        low=float(c["low"]),
                        close=float(c["close"]),
                        volume=float(c["volume"]),
                        turnover=c.get("turnover"),
                        source="bybit_rest_history",
                    )
                    batch_new_count += 1
                
                all_candles.extend(batch_valid_candles)
                
                # æ›´æ–°æ¸¸æ ‡ï¼šä½¿ç”¨æœ¬æ‰¹æ¬¡ä¸­æœ€æ–°ï¼ˆæœ€å¤§ï¼‰çš„æ—¶é—´æˆ³ + 1ä¸ªå‘¨æœŸ
                # å‚è€ƒ _rest_backfill_range çš„å®ç°ï¼šlast = int(candles[-1]["start_ms"])
                # åè½¬å candles[-1] æ˜¯æœ€æ–°çš„ï¼Œåº”è¯¥ç”¨æœ€æ–°çš„æ—¶é—´æˆ³æ¨è¿›æ¸¸æ ‡
                # æ³¨æ„ï¼šè¿™é‡Œåº”è¯¥ç”¨åè½¬åçš„ candles[-1]ï¼Œå³æœ¬æ‰¹æ¬¡ä¸­æœ€æ–°çš„Kçº¿
                # ä½†éœ€è¦ç¡®ä¿è¿™ä¸ªæ—¶é—´æˆ³åœ¨æ—¶é—´èŒƒå›´å†…
                last = int(candles[-1]["start_ms"])  # åè½¬åæœ€æ–°ï¼ˆæœ€å¤§ï¼‰çš„æ—¶é—´æˆ³
                
                # å¦‚æœ last ä¸åœ¨æ—¶é—´èŒƒå›´å†…ï¼Œä½¿ç”¨ max_start_msï¼ˆè¿‡æ»¤åçš„æœ€å¤§å€¼ï¼‰
                if last < start_ms or last > end_ms:
                    last = max_start_ms
                
                next_cursor = last + tf_ms
                
                # å¦‚æœæ¸¸æ ‡å·²ç»è¶…è¿‡ç»“æŸæ—¶é—´ï¼Œè¯´æ˜å·²è·å–å®Œ
                if next_cursor > end_ms:
                    print_info(f"æ‰¹æ¬¡ {batch_count}ï¼šæ¸¸æ ‡å·²è¶…è¿‡ç»“æŸæ—¶é—´ï¼ˆ{datetime.fromtimestamp(next_cursor/1000).strftime('%Y-%m-%d %H:%M:%S')} > {datetime.fromtimestamp(end_ms/1000).strftime('%Y-%m-%d %H:%M:%S')}ï¼‰ï¼Œæ•°æ®è·å–å®Œæˆ")
                    break
                
                # å¦‚æœæ¸¸æ ‡æ²¡æœ‰æ¨è¿›ï¼Œé˜²æ­¢æ­»å¾ªç¯ï¼ˆå‚è€ƒ _rest_backfill_rangeï¼‰
                if next_cursor <= cursor:
                    print_warning(f"æ‰¹æ¬¡ {batch_count}ï¼šæ¸¸æ ‡æœªæ¨è¿›ï¼ˆ{datetime.fromtimestamp(cursor/1000).strftime('%Y-%m-%d %H:%M:%S')} -> {datetime.fromtimestamp(next_cursor/1000).strftime('%Y-%m-%d %H:%M:%S')}ï¼‰ï¼Œå¯èƒ½å·²è·å–å®Œæ‰€æœ‰æ•°æ®")
                    print_warning(f"  æœ¬æ‰¹æ¬¡æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(min_start_ms/1000).strftime('%Y-%m-%d %H:%M:%S')} è‡³ {datetime.fromtimestamp(max_start_ms/1000).strftime('%Y-%m-%d %H:%M:%S')}ï¼Œè·å–äº† {batch_new_count} æ ¹")
                    print_warning(f"  last Kçº¿æ—¶é—´: {datetime.fromtimestamp(last/1000).strftime('%Y-%m-%d %H:%M:%S')}ï¼Œtf_ms={tf_ms}")
                    break
                
                cursor = next_cursor
                
                # æ‰“å°æ‰¹æ¬¡ä¿¡æ¯ï¼ˆæ— è®ºæ˜¯å¦ç»§ç»­ï¼‰
                print(f"  å·²è·å–æ‰¹æ¬¡ {batch_count}ï¼Œä¿å­˜äº† {batch_new_count} æ ¹ï¼Œæ—¶é—´èŒƒå›´: {datetime.fromtimestamp(min_start_ms/1000).strftime('%Y-%m-%d %H:%M:%S')} è‡³ {datetime.fromtimestamp(max_start_ms/1000).strftime('%Y-%m-%d %H:%M:%S')}ï¼Œä¸‹ä¸€æ‰¹æ¸¸æ ‡: {datetime.fromtimestamp(next_cursor/1000).strftime('%Y-%m-%d %H:%M:%S')}")
                
                # å¦‚æœè¿”å›çš„Kçº¿å°‘äº1000æ ¹ï¼Œè¯´æ˜å·²åˆ°è¾¾è¾¹ç•Œ
                if len(candles) < 1000:
                    print_info(f"æ‰¹æ¬¡ {batch_count}ï¼šè¿”å›çš„Kçº¿å°‘äº1000æ ¹ï¼ˆ{len(candles)}æ ¹ï¼‰ï¼Œå·²åˆ°è¾¾è¾¹ç•Œ")
                    break
                
                time.sleep(0.2)  # é¿å… API é™æµ
                
            except Exception as e:
                print_error(f"è·å–æ‰¹æ¬¡ {batch_count} å¤±è´¥: {e}")
                break
        
        print_success(f"ä» API è·å–å¹¶ä¿å­˜äº†çº¦ {len(all_candles)} æ ¹ K çº¿")
        print()
        
        # é‡æ–°ä»æ•°æ®åº“è¯»å–
        bars = get_bars_range(settings.database_url, symbol=symbol, timeframe=tf, start_close_time_ms=start_ms, end_close_time_ms=end_ms)
        
        # è®¡ç®—ä¿®å¤è¿›åº¦
        print_success(f"æ•°æ®ä¿®å¤å®Œæˆï¼Œç°åœ¨æœ‰ {len(bars)} æ ¹ K çº¿ï¼ˆæœ¬æ¬¡è·å–çº¦ {len(all_candles)} æ ¹ï¼‰")
        print()
        
        # å¦‚æœä¿®å¤åæ•°æ®ä»ç„¶ä¸è¶³ï¼Œç»™å‡ºæç¤º
        if len(bars) < estimated_bars * 0.8:
            remaining_pct = (1 - len(bars) / estimated_bars) * 100
            print_warning(f"ä¿®å¤åæ•°æ®ä»ä¸å®Œæ•´: æ‰¾åˆ° {len(bars)} æ ¹ï¼Œé¢„è®¡éœ€è¦çº¦ {estimated_bars} æ ¹ï¼ˆä»ç¼ºå¤±çº¦ {remaining_pct:.1f}%ï¼‰")
            print_warning("å¯èƒ½çš„åŸå› : 1) Bybit API é™åˆ¶ 2) æ—¶é—´èŒƒå›´è¿‡å¤§ 3) ç½‘ç»œé—®é¢˜")
            print_info("å°†ç»§ç»­ä½¿ç”¨ç°æœ‰æ•°æ®è¿›è¡Œåˆ†æ...")
            print()
    else:
        # æ•°æ®å®Œæ•´ï¼Œç›´æ¥ä½¿ç”¨
        pass
    
    print_info(f"æ•°æ®åº“ä¸­æ‰¾åˆ° {len(bars)} æ ¹ K çº¿")
    
    if len(bars) < 200:
        print_error(f"æ•°æ®é‡ä¸è¶³: è‡³å°‘éœ€è¦ 200 æ ¹ K çº¿ï¼Œå½“å‰åªæœ‰ {len(bars)} æ ¹")
        sys.exit(1)
    
    # 2. å¯¹æ¯ä¸ª bar è¿è¡Œç­–ç•¥é€»è¾‘ï¼ˆä»ç¬¬ 120 æ ¹å¼€å§‹ï¼Œå› ä¸ºéœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
    print_info("å¼€å§‹åˆ†æç­–ç•¥ä¿¡å·...")
    print()
    
    signals: List[Dict[str, Any]] = []
    min_bars_needed = 120
    
    # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ†æ
    for i in range(min_bars_needed, len(bars)):
        # è·å–æœ€è¿‘ 500 æ ¹ barsï¼ˆç­–ç•¥éœ€è¦ï¼‰
        window_bars = bars[max(0, i - 499):i + 1]
        
        if len(window_bars) < min_bars_needed:
            continue
        
        current_bar = bars[i]
        candles = [Candle(open=b["open"], high=b["high"], low=b["low"], close=b["close"], volume=b["volume"]) for b in window_bars]
        close = [c.close for c in candles]
        high = [c.high for c in candles]
        low = [c.low for c in candles]
        
        # 1) æ£€æµ‹ä¸‰æ®µèƒŒç¦»
        setup = detect_three_segment_divergence(close=close, high=high, low=low)
        if setup is None:
            continue
        
        bias = setup.direction  # LONG/SHORT
        
        # 2) Vegas å¼ºé—¨æ§›ï¼ˆåŒå‘å¿…é¡»ï¼‰
        vs = vegas_state(close)
        if bias == "LONG" and vs != "Bullish":
            continue
        if bias == "SHORT" and vs != "Bearish":
            continue
        
        # 3) confirmations
        hits: List[str] = []
        if engulfing(candles[-2:], bias):
            hits.append("ENGULFING")
        if rsi_divergence(candles, bias):
            hits.append("RSI_DIV")
        if obv_divergence(candles, bias):
            hits.append("OBV_DIV")
        if fvg_proximity(candles, bias):
            hits.append("FVG_PROXIMITY")
        
        if len(hits) < settings.min_confirmations:
            continue
        
        # ç­–ç•¥ç±»å‹æ ‡è¯†ï¼ˆæŒ‰ç¡®è®¤é¡¹ç»„åˆï¼‰
        strategy_type = "MACD_3SEG_DIVERGENCE"
        hits_key = "+".join(sorted(hits))  # ç¡®è®¤é¡¹ç»„åˆä½œä¸ºç­–ç•¥å˜ä½“æ ‡è¯†
        
        # ç­–ç•¥ç­›é€‰
        if strategy_filter:
            if strategy_filter != "ALL":
                if strategy_filter_confirmations:
                    # æŒ‰ç¡®è®¤é¡¹ç»„åˆç­›é€‰
                    if not strategy_filter_confirmations.issubset(set(hits)):
                        continue
                elif strategy_filter != "MACD_3SEG_DIVERGENCE":
                    # å…¶ä»–ç­–ç•¥ç±»å‹ï¼ˆé¢„ç•™æ‰©å±•ï¼‰
                    continue
        
        # æ‰¾åˆ°ä¿¡å·ï¼
        signal = {
            "close_time_ms": current_bar["close_time_ms"],
            "bias": bias,
            "vegas_state": vs,
            "hits": hits,
            "hit_count": len(hits),
            "price": current_bar["close"],
            "strategy_type": strategy_type,
            "strategy_variant": hits_key,  # ç­–ç•¥å˜ä½“ï¼ˆç¡®è®¤é¡¹ç»„åˆï¼‰
        }
        signals.append(signal)
        
        if len(signals) % 50 == 0:
            print(f"  å·²åˆ†æ {i+1}/{len(bars)} æ ¹ K çº¿ï¼Œæ‰¾åˆ° {len(signals)} ä¸ªä¿¡å·...")
    
    print_success(f"åˆ†æå®Œæˆï¼å…±æ‰¾åˆ° {len(signals)} ä¸ªç­–ç•¥ä¿¡å·")
    print()
    
    # 3. ç»Ÿè®¡æŠ¥å‘Š
    print("=" * 60)
    print("  ç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 60)
    print()
    
    # æŒ‰ bias ç»Ÿè®¡
    long_count = sum(1 for s in signals if s["bias"] == "LONG")
    short_count = sum(1 for s in signals if s["bias"] == "SHORT")
    
    print_info(f"æ€»ä¿¡å·æ•°: {len(signals)}")
    print(f"  - LONG: {long_count} ({long_count*100/max(len(signals),1):.1f}%)")
    print(f"  - SHORT: {short_count} ({short_count*100/max(len(signals),1):.1f}%)")
    print()
    
    # æŒ‰ç¡®è®¤é¡¹ç»Ÿè®¡
    confirmation_counts = {}
    for s in signals:
        for hit in s["hits"]:
            confirmation_counts[hit] = confirmation_counts.get(hit, 0) + 1
    
    print_info("ç¡®è®¤é¡¹ç»Ÿè®¡:")
    for hit, count in sorted(confirmation_counts.items(), key=lambda x: -x[1]):
        print(f"  - {hit}: {count} ({count*100/max(len(signals),1):.1f}%)")
    print()
    
    # æŒ‰ hit_count ç»Ÿè®¡
    hit_count_stats = {}
    for s in signals:
        cnt = s["hit_count"]
        hit_count_stats[cnt] = hit_count_stats.get(cnt, 0) + 1
    
    print_info("ç¡®è®¤é¡¹æ•°é‡åˆ†å¸ƒ:")
    for cnt in sorted(hit_count_stats.keys()):
        print(f"  - {cnt} ä¸ªç¡®è®¤é¡¹: {hit_count_stats[cnt]} ä¸ªä¿¡å· ({hit_count_stats[cnt]*100/max(len(signals),1):.1f}%)")
    print()
    
    # æŒ‰ç­–ç•¥å˜ä½“ï¼ˆç¡®è®¤é¡¹ç»„åˆï¼‰ç»Ÿè®¡
    strategy_variant_stats = {}
    for s in signals:
        variant = s.get("strategy_variant", "")
        if not variant:
            variant = "+".join(sorted(s.get("hits", [])))
        strategy_variant_stats[variant] = strategy_variant_stats.get(variant, 0) + 1
    
    print_info("æŒ‰ç­–ç•¥å˜ä½“ï¼ˆç¡®è®¤é¡¹ç»„åˆï¼‰ç»Ÿè®¡:")
    for variant, count in sorted(strategy_variant_stats.items(), key=lambda x: -x[1]):
        variant_display = variant if variant else "(æ— )"
        print(f"  - {variant_display}: {count} ä¸ªä¿¡å· ({count*100/max(len(signals),1):.1f}%)")
    print()
    
    # æŒ‰å¹´/æœˆç»Ÿè®¡
    from collections import defaultdict
    by_year_month = defaultdict(int)
    for s in signals:
        dt = datetime.fromtimestamp(s["close_time_ms"] / 1000)
        key = f"{dt.year}-{dt.month:02d}"
        by_year_month[key] += 1
    
    print_info("æŒ‰å¹´æœˆåˆ†å¸ƒ:")
    for key in sorted(by_year_month.keys()):
        print(f"  - {key}: {by_year_month[key]} ä¸ªä¿¡å·")
    print()
    
    # è¾“å‡ºä¿¡å·ç¤ºä¾‹ï¼ˆåŒ…å«æ—¥æœŸæ—¶é—´ã€Kçº¿å‘¨æœŸã€ä¿¡å·åç§°ç­‰ï¼‰
    if signals:
        print_info("ä¿¡å·ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
        print()
        print(f"{'åºå·':<6} {'æ—¥æœŸæ—¶é—´':<20} {'Kçº¿å‘¨æœŸ':<10} {'æ–¹å‘':<8} {'ä»·æ ¼':<12} {'ç­–ç•¥å˜ä½“':<40} {'ç¡®è®¤é¡¹æ•°é‡':<10}")
        print("-" * 120)
        for idx, s in enumerate(signals[:10], start=1):
            dt = datetime.fromtimestamp(s["close_time_ms"] / 1000)
            dt_str = dt.strftime("%Y-%m-%d %H:%M:%S")
            variant = s.get("strategy_variant", "+".join(sorted(s.get("hits", []))))
            variant_display = variant[:38] if len(variant) > 38 else variant
            print(f"{idx:<6} {dt_str:<20} {tf:<10} {s['bias']:<8} {s['price']:<12.2f} {variant_display:<40} {s['hit_count']:<10}")
        print()
        
        if args.show_all_signals:
            print_info(f"æ‰€æœ‰ä¿¡å·è¯¦æƒ…ï¼ˆå…± {len(signals)} ä¸ªï¼‰:")
            print()
            print(f"{'åºå·':<6} {'æ—¥æœŸæ—¶é—´':<20} {'Kçº¿å‘¨æœŸ':<10} {'æ–¹å‘':<8} {'ä»·æ ¼':<12} {'ç­–ç•¥å˜ä½“':<40} {'ç¡®è®¤é¡¹':<60} {'VegasçŠ¶æ€':<12}")
            print("-" * 180)
            for idx, s in enumerate(signals, start=1):
                dt = datetime.fromtimestamp(s["close_time_ms"] / 1000)
                dt_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                variant = s.get("strategy_variant", "+".join(sorted(s.get("hits", []))))
                variant_display = variant[:38] if len(variant) > 38 else variant
                hits_display = ", ".join(s.get("hits", []))[:58] if len(", ".join(s.get("hits", []))) > 58 else ", ".join(s.get("hits", []))
                print(f"{idx:<6} {dt_str:<20} {tf:<10} {s['bias']:<8} {s['price']:<12.2f} {variant_display:<40} {hits_display:<60} {s.get('vegas_state', 'N/A'):<12}")
            print()
    
    # è¾“å‡ºæ‰€æœ‰å¯é€‰çš„ç­–ç•¥ç±»å‹
    print_info("æ‰€æœ‰å¯ç”¨çš„ç­–ç•¥ç±»å‹:")
    print("  1. MACD_3SEG_DIVERGENCE - MACD ä¸‰æ®µèƒŒç¦»ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰")
    print()
    print_info("æ‰€æœ‰å¯ç”¨çš„ç¡®è®¤é¡¹ç»„åˆï¼ˆç­–ç•¥å˜ä½“ï¼‰:")
    all_confirmation_types = ["ENGULFING", "RSI_DIV", "OBV_DIV", "FVG_PROXIMITY"]
    
    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
    from itertools import combinations
    variant_examples = []
    for r in range(2, len(all_confirmation_types) + 1):
        for combo in combinations(all_confirmation_types, r):
            combo_key = "+".join(sorted(combo))
            # æ£€æŸ¥è¿™ä¸ªç»„åˆæ˜¯å¦åœ¨å®é™…ä¿¡å·ä¸­å‡ºç°
            count = strategy_variant_stats.get(combo_key, 0)
            variant_examples.append((combo_key, count))
    
    # æŒ‰å‡ºç°é¢‘ç‡æ’åº
    variant_examples.sort(key=lambda x: -x[1])
    
    print(f"  {'ç­–ç•¥å˜ä½“':<50} {'å‡ºç°æ¬¡æ•°':<12} {'å æ¯”':<10}")
    print(f"  {'-' * 70}")
    for variant, count in variant_examples:
        pct = count * 100 / max(len(signals), 1)
        print(f"  {variant:<50} {count:<12} {pct:.1f}%")
    print()
    
    # 4. ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    Path("reports").mkdir(exist_ok=True)
    ts = int(time.time())
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶åï¼ˆæ ¹æ®æ—¶é—´èŒƒå›´å‚æ•°ï¼‰
    if args.months:
        time_suffix = f"{args.months}months"
    elif args.days:
        time_suffix = f"{args.days}days"
    elif args.start_date:
        time_suffix = f"{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}"
    else:
        time_suffix = f"{years}years"
    
    report_path = Path("reports") / f"signal_analysis_{symbol}_{tf}_{time_suffix}_{ts}.json"
    
    report_data = {
        "symbol": symbol,
        "timeframe": tf,
        "time_range": {
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "years": years if not args.months and not args.days else None,
            "months": args.months if args.months else None,
            "days": args.days if args.days else None,
        },
        "total_bars": len(bars),
        "total_signals": len(signals),
        "statistics": {
            "by_bias": {
                "LONG": long_count,
                "SHORT": short_count,
            },
            "by_confirmations": confirmation_counts,
            "by_hit_count": hit_count_stats,
            "by_strategy_variant": dict(strategy_variant_stats),
            "by_year_month": dict(by_year_month),
        },
        "strategy_filter": strategy_filter if strategy_filter else "ALL",
        "signals": signals if args.show_all_signals or len(signals) <= 1000 else signals[-1000:],  # å¦‚æœæ˜¾ç¤ºæ‰€æœ‰ä¿¡å·æˆ–æ•°é‡å°‘ï¼Œä¿å­˜å…¨éƒ¨ï¼›å¦åˆ™ä¿å­˜æœ€è¿‘1000ä¸ª
        "all_strategy_variants": [
            {"variant": v, "count": c, "percentage": c*100/max(len(signals),1)}
            for v, c in sorted(strategy_variant_stats.items(), key=lambda x: -x[1])
        ],
    }
    
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print_success(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    print()

# ==================== åŸºç¡€è®¾æ–½åˆå§‹åŒ–åŠŸèƒ½ ====================

def cmd_init_db():
    """æ•°æ®åº“è¿ç§»åˆå§‹åŒ–å‘½ä»¤"""
    print("=" * 60)
    print("  æ•°æ®åº“è¿ç§»åˆå§‹åŒ–")
    print("=" * 60)
    print()
    
    try:
        from scripts.init_db import main as init_db_main
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    init_db_main()

def cmd_init_streams():
    """Redis Streams åˆå§‹åŒ–å‘½ä»¤"""
    print("=" * 60)
    print("  Redis Streams åˆå§‹åŒ–")
    print("=" * 60)
    print()
    
    try:
        from scripts.init_streams import main as init_streams_main
    except ImportError as e:
        print_error(f"å¯¼å…¥å¤±è´¥: {e}")
        sys.exit(1)
    
    init_streams_main()

# ==================== ä¸»å‡½æ•° ====================

def main():
    parser = argparse.ArgumentParser(
        description="äº¤æ˜“ç³»ç»Ÿæµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # å‡†å¤‡æ£€æŸ¥
  python -m scripts.trading_test_tool prepare

  # æŸ¥çœ‹æŒä»“
  python -m scripts.trading_test_tool positions
  python -m scripts.trading_test_tool positions --detailed

  # æ¸…ç†æŒä»“
  python -m scripts.trading_test_tool clean --all
  python -m scripts.trading_test_tool clean --all --yes
  python -m scripts.trading_test_tool clean <position_id>

  # å¿«é€Ÿæµ‹è¯•ä¸‹å•ï¼ˆæ¨èï¼Œæœ€ç®€å•ï¼‰
  python -m scripts.trading_test_tool quick-test
  
  # å¿«é€Ÿæµ‹è¯•ä¸‹å•ï¼ˆæŒ‡å®šå‚æ•°ï¼‰
  python -m scripts.trading_test_tool quick-test \\
    --symbol ETHUSDT \\
    --side SELL
  
  # æ‰§è¡Œæµ‹è¯•ä¸‹å•ï¼ˆè‡ªåŠ¨è·å–ä»·æ ¼ï¼‰
  python -m scripts.trading_test_tool test \\
    --symbol BTCUSDT \\
    --side BUY

  # æ‰§è¡Œæµ‹è¯•ä¸‹å•ï¼ˆæ‰‹åŠ¨æŒ‡å®šä»·æ ¼ï¼‰
  python -m scripts.trading_test_tool test \\
    --symbol BTCUSDT \\
    --side BUY \\
    --entry-price 30000 \\
    --sl-price 29000

  # æ‰§è¡Œæµ‹è¯•ä¸‹å•ï¼ˆè‡ªå®šä¹‰æ­¢æŸè·ç¦»ï¼‰
  python -m scripts.trading_test_tool test \\
    --symbol BTCUSDT \\
    --side BUY \\
    --sl-distance-pct 0.03

  # æŸ¥çœ‹è®¢å•
  python -m scripts.trading_test_tool orders
  python -m scripts.trading_test_tool orders --idempotency-key idem-xxx

  # è¯Šæ–­ä¸‹å•å¤±è´¥åŸå› 
  python -m scripts.trading_test_tool diagnose \\
    --symbol BTCUSDT \\
    --side BUY
  
  # è¯Šæ–­ä¿¡å·ç”Ÿæˆé—®é¢˜
  python -m scripts.trading_test_tool diagnose-signals \\
    --symbol BTCUSDT \\
    --timeframe 1h

  # åŒæ­¥æŒä»“ï¼ˆæ£€æŸ¥å¹¶ä¿®å¤ä¸ä¸€è‡´ï¼‰
  python -m scripts.trading_test_tool sync
  python -m scripts.trading_test_tool sync --dry-run  # ä»…æ£€æŸ¥ï¼Œä¸ä¿®æ”¹

  # å¹³ä»“æµ‹è¯•ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰
  python -m scripts.trading_test_tool close-test \\
    --symbol BTCUSDT --side BUY --entry-price 30000 --sl-price 29000

  # é£æ§é—¸é—¨æµ‹è¯•ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰
  python -m scripts.trading_test_tool gates-test --reset-db

  # å›æ”¾å›æµ‹
  python -m scripts.trading_test_tool replay \\
    --symbol BTCUSDT --timeframe 60 --limit 2000

  # é™æµå™¨è‡ªæµ‹
  python -m scripts.trading_test_tool ratelimit-test

  # WebSocket å¤„ç†è‡ªæµ‹
  python -m scripts.trading_test_tool ws-test

  # æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥
  python -m scripts.trading_test_tool db-check

  # ç¦»çº¿å›æµ‹
  python -m scripts.trading_test_tool backtest \\
    --symbol BTCUSDT --timeframe 1h --limit 5000 --trail ATR

  # å›æ”¾+æŠ¥å‘Šç”Ÿæˆ
  python -m scripts.trading_test_tool replay-report \\
    --symbol BTCUSDT --timeframe 60 --limit 2000

  # å†å²ä¿¡å·åˆ†æï¼ˆåˆ†æè¿‡å»3å¹´çš„ç­–ç•¥ä¿¡å·ï¼Œæ‰€æœ‰ç­–ç•¥ï¼‰
  python -m scripts.trading_test_tool analyze-signals \\
    --symbol BTCUSDT --timeframe 1h --years 3

  # å†å²ä¿¡å·åˆ†æï¼ˆä» API è·å–æ•°æ®ï¼‰
  python -m scripts.trading_test_tool analyze-signals \\
    --symbol BTCUSDT --timeframe 1h --years 3 --fetch-from-api

  # å†å²ä¿¡å·åˆ†æï¼ˆç­›é€‰ç‰¹å®šç­–ç•¥å˜ä½“ï¼šåŒ…å« ENGULFING å’Œ RSI_DIVï¼‰
  python -m scripts.trading_test_tool analyze-signals \\
    --symbol BTCUSDT --timeframe 1h --years 3 --strategy ENGULFING+RSI_DIV

  # å†å²ä¿¡å·åˆ†æï¼ˆç­›é€‰ MACD ä¸‰æ®µèƒŒç¦»ç­–ç•¥ï¼‰
  python -m scripts.trading_test_tool analyze-signals \\
    --symbol BTCUSDT --timeframe 1h --years 3 --strategy MACD_3SEG_DIVERGENCE

  # æ•°æ®åº“è¿ç§»åˆå§‹åŒ–
  python -m scripts.trading_test_tool init-db

  # Redis Streams åˆå§‹åŒ–
  python -m scripts.trading_test_tool init-streams
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # prepare å‘½ä»¤
    subparsers.add_parser('prepare', help='å‡†å¤‡æ£€æŸ¥ï¼ˆæ£€æŸ¥é…ç½®ã€æœåŠ¡çŠ¶æ€ç­‰ï¼‰')
    
    # positions å‘½ä»¤
    pos_parser = subparsers.add_parser('positions', help='æŸ¥çœ‹ OPEN æŒä»“')
    pos_parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # clean å‘½ä»¤
    clean_parser = subparsers.add_parser('clean', help='æ¸…ç†æŒä»“')
    clean_parser.add_argument('position_id', nargs='?', help='æŒä»“ IDï¼ˆå¯é€‰ï¼‰')
    clean_parser.add_argument('--all', action='store_true', help='æ¸…ç†æ‰€æœ‰ OPEN æŒä»“')
    clean_parser.add_argument('--yes', action='store_true', help='è·³è¿‡ç¡®è®¤æç¤º')
    
    # test å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='æ‰§è¡Œæµ‹è¯•ä¸‹å•ï¼ˆâš ï¸ ä¼šçœŸå®ä¸‹å•ï¼ï¼‰')
    test_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    test_parser.add_argument('--side', required=True, choices=['BUY', 'SELL'], help='æ–¹å‘ï¼šBUY æˆ– SELL')
    test_parser.add_argument('--entry-price', type=float, default=None, help='å…¥åœºä»·æ ¼ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨è·å–å¸‚åœºä»·æ ¼ï¼‰')
    test_parser.add_argument('--sl-price', type=float, default=None, help='æ­¢æŸä»·æ ¼ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨è®¡ç®—ï¼‰')
    test_parser.add_argument('--sl-distance-pct', type=float, default=0.02, help='æ­¢æŸè·ç¦»ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤: 0.02ï¼Œå³ 2%%ï¼‰')
    test_parser.add_argument('--timeframe', default='15m', help='æ—¶é—´æ¡†æ¶ï¼ˆé»˜è®¤: 15mï¼‰')
    test_parser.add_argument('--wait-seconds', type=int, default=30, help='ç­‰å¾…æ‰§è¡Œçš„æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 30ï¼‰')
    test_parser.add_argument('--confirm', action='store_true', help='è·³è¿‡ç¡®è®¤æç¤ºï¼ˆè°¨æ…ä½¿ç”¨ï¼‰')
    test_parser.add_argument('--auto-diagnose', action='store_true', help='ä¸‹å•å‰è‡ªåŠ¨è¿è¡Œè¯Šæ–­æ£€æŸ¥')
    
    # quick-test å‘½ä»¤ï¼ˆæ•´åˆ quick_test_order.sh åŠŸèƒ½ï¼‰
    quick_test_parser = subparsers.add_parser('quick-test', help='å¿«é€Ÿæµ‹è¯•ä¸‹å•ï¼ˆé»˜è®¤å‚æ•°ï¼Œè‡ªåŠ¨è¯Šæ–­ï¼Œè·³è¿‡ç¡®è®¤ï¼‰')
    quick_test_parser.add_argument('--symbol', default='BTCUSDT', help='äº¤æ˜“å¯¹ï¼ˆé»˜è®¤: BTCUSDTï¼‰')
    quick_test_parser.add_argument('--side', default='BUY', choices=['BUY', 'SELL'], help='æ–¹å‘ï¼ˆé»˜è®¤: BUYï¼‰')
    quick_test_parser.add_argument('--timeframe', default='1h', help='æ—¶é—´æ¡†æ¶ï¼ˆé»˜è®¤: 1hï¼‰')
    quick_test_parser.add_argument('--sl-distance-pct', type=float, default=0.02, help='æ­¢æŸè·ç¦»ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤: 0.02ï¼Œå³ 2%%ï¼‰')
    quick_test_parser.add_argument('--wait-seconds', type=int, default=30, help='ç­‰å¾…æ‰§è¡Œçš„æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 30ï¼‰')
    
    # orders å‘½ä»¤
    orders_parser = subparsers.add_parser('orders', help='æŸ¥çœ‹è®¢å•')
    orders_parser.add_argument('--idempotency-key', help='æŒ‰ idempotency_key è¿‡æ»¤')
    orders_parser.add_argument('--limit', type=int, default=10, help='é™åˆ¶è¿”å›æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰')
    
    # diagnose å‘½ä»¤
    diagnose_parser = subparsers.add_parser('diagnose', help='è¯Šæ–­ä¸‹å•å¤±è´¥åŸå› ')
    diagnose_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    diagnose_parser.add_argument('--side', required=True, choices=['BUY', 'SELL'], help='æ–¹å‘ï¼šBUY æˆ– SELL')
    
    # diagnose-signals å‘½ä»¤
    diagnose_signals_parser = subparsers.add_parser('diagnose-signals', help='è¯Šæ–­ä¿¡å·ç”Ÿæˆé—®é¢˜')
    diagnose_signals_parser.add_argument('--symbol', default='BTCUSDT', help='äº¤æ˜“å¯¹ï¼ˆé»˜è®¤: BTCUSDTï¼‰')
    diagnose_signals_parser.add_argument('--timeframe', default='1h', help='æ—¶é—´æ¡†æ¶ï¼ˆé»˜è®¤: 1hï¼‰')
    
    # sync å‘½ä»¤
    sync_parser = subparsers.add_parser('sync', help='åŒæ­¥æ•°æ®åº“æŒä»“ä¸äº¤æ˜“æ‰€æŒä»“')
    sync_parser.add_argument('--dry-run', action='store_true', help='ä»…æ£€æŸ¥ï¼Œä¸å®é™…ä¿®æ”¹æ•°æ®åº“')
    
    # close-test å‘½ä»¤
    close_test_parser = subparsers.add_parser('close-test', help='å¹³ä»“æµ‹è¯•ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰')
    close_test_parser.add_argument('--symbol', default='BCHUSDT', help='äº¤æ˜“å¯¹ï¼ˆé»˜è®¤: BCHUSDTï¼‰')
    close_test_parser.add_argument('--side', default='SELL', choices=['BUY', 'SELL'], help='æ–¹å‘ï¼ˆé»˜è®¤: SELLï¼‰')
    close_test_parser.add_argument('--timeframe', default='15m', help='æ—¶é—´æ¡†æ¶ï¼ˆé»˜è®¤: 15mï¼‰')
    close_test_parser.add_argument('--entry-price', type=float, default=617.5, help='å…¥åœºä»·æ ¼ï¼ˆé»˜è®¤: 617.5ï¼‰')
    close_test_parser.add_argument('--sl-price', type=float, default=630.0, help='æ­¢æŸä»·æ ¼ï¼ˆé»˜è®¤: 630.0ï¼‰')
    close_test_parser.add_argument('--wait-before-close', type=int, default=3, help='æŒä»“åˆ›å»ºåç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 3ï¼‰')
    close_test_parser.add_argument('--wait-after-close', type=int, default=3, help='å¹³ä»“åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 3ï¼‰')
    close_test_parser.add_argument('--close-price', type=float, default=623.7579, help='å¼ºåˆ¶å¹³ä»“ä»·æ ¼ï¼ˆé»˜è®¤: 623.7579ï¼‰')
    
    # gates-test å‘½ä»¤
    gates_test_parser = subparsers.add_parser('gates-test', help='é£æ§é—¸é—¨æµ‹è¯•ï¼ˆPAPER/BACKTEST æ¨¡å¼ï¼‰')
    gates_test_parser.add_argument('--reset-db', action='store_true', help='æµ‹è¯•å‰é‡ç½®æ•°æ®åº“ï¼ˆTRUNCATE execution tablesï¼‰')
    gates_test_parser.add_argument('--wait', type=int, default=10, help='ç­‰å¾…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 10ï¼‰')
    
    # replay å‘½ä»¤
    replay_parser = subparsers.add_parser('replay', help='å›æ”¾å›æµ‹ï¼ˆä½¿ç”¨å†å² bars å›æ”¾ bar_close äº‹ä»¶ï¼‰')
    replay_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    replay_parser.add_argument('--timeframe', required=True, help='æ—¶é—´æ¡†æ¶ï¼Œå¦‚ 60(1h)/240(4h)/D(1d)')
    replay_parser.add_argument('--limit', type=int, default=0, help='ä» DB è¯»å–æœ€è¿‘ N æ ¹ bars å›æ”¾')
    replay_parser.add_argument('--start-ms', type=int, default=0, help='å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰')
    replay_parser.add_argument('--end-ms', type=int, default=0, help='ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰')
    replay_parser.add_argument('--run-id', default='', help='è¿è¡Œ IDï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    replay_parser.add_argument('--sleep-ms', type=int, default=0, help='æ¯æ¬¡å‘å¸ƒäº‹ä»¶åçš„å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼Œé»˜è®¤: 0ï¼‰')
    replay_parser.add_argument('--fetch', action='store_true', help='å…ˆä» Bybit REST æ‹‰å– bars å†™åº“')
    replay_parser.add_argument('--fetch-limit', type=int, default=2000, help='æ‹‰å–çš„ bars æ•°é‡ï¼ˆé»˜è®¤: 2000ï¼‰')
    
    # ratelimit-test å‘½ä»¤
    subparsers.add_parser('ratelimit-test', help='é™æµå™¨è‡ªæµ‹ï¼ˆä¸è°ƒç”¨ Bybitï¼Œä»…æµ‹è¯•é™æµé€»è¾‘ï¼‰')
    
    # ws-test å‘½ä»¤
    subparsers.add_parser('ws-test', help='WebSocket å¤„ç†è‡ªæµ‹ï¼ˆæµ‹è¯•æ¶ˆæ¯è§£æä¸è·¯ç”±ï¼‰')
    
    # db-check å‘½ä»¤
    subparsers.add_parser('db-check', help='æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥')
    
    # backtest å‘½ä»¤
    backtest_parser = subparsers.add_parser('backtest', help='ç¦»çº¿å›æµ‹ï¼ˆè¯»å– barsï¼Œæ¨¡æ‹Ÿæ‰§è¡Œï¼‰')
    backtest_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    backtest_parser.add_argument('--timeframe', required=True, help='æ—¶é—´æ¡†æ¶ï¼Œå¦‚ 60/240/D')
    backtest_parser.add_argument('--limit', type=int, default=5000, help='K çº¿æ•°é‡é™åˆ¶')
    backtest_parser.add_argument('--trail', choices=['ATR', 'PIVOT'], default='ATR', help='è¿½è¸ªæ­¢æŸæ¨¡å¼')
    backtest_parser.add_argument('--atr-period', type=int, default=14, dest='atr_period', help='ATR å‘¨æœŸ')
    backtest_parser.add_argument('--atr-mult', type=float, default=2.0, dest='atr_mult', help='ATR å€æ•°')
    backtest_parser.add_argument('--write-db', action='store_true', help='å°†å›æµ‹ç»“æœå†™å…¥æ•°æ®åº“')
    backtest_parser.add_argument('--run-id', default='', help='å¯é€‰ï¼šæŒ‡å®š run_id')
    
    # replay-report å‘½ä»¤
    replay_report_parser = subparsers.add_parser('replay-report', help='å›æ”¾å›æµ‹ + ç­‰å¾… + æŠ¥å‘Šç”Ÿæˆ')
    replay_report_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    replay_report_parser.add_argument('--timeframe', required=True, help='æ—¶é—´æ¡†æ¶ï¼Œå¦‚ 60/240/D')
    replay_report_parser.add_argument('--limit', type=int, default=2000, help='K çº¿æ•°é‡é™åˆ¶')
    replay_report_parser.add_argument('--run-id', default='', help='å¯é€‰ï¼šæŒ‡å®š run_id')
    replay_report_parser.add_argument('--timeout-sec', type=int, default=300, help='ç­‰å¾…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    replay_report_parser.add_argument('--api-url', default='', help='å¯é€‰ï¼šAPI æœåŠ¡åœ°å€ï¼Œç”¨äºè·å– compare ä¿¡æ¯')
    
    # analyze-signals å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze-signals', help='å†å²ä¿¡å·åˆ†æï¼šåˆ†æè¿‡å»Nå¹´çš„ç­–ç•¥ä¿¡å·å‡ºç°æ¬¡æ•°')
    analyze_parser.add_argument('--symbol', required=True, help='äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT')
    analyze_parser.add_argument('--timeframe', required=True, help='æ—¶é—´æ¡†æ¶ï¼Œå¦‚ 1m/5m/15m/30m/1h/4h/1d')
    
    # æ—¶é—´èŒƒå›´å‚æ•°ï¼ˆå¤šç§æ–¹å¼ï¼Œäº’æ–¥ï¼‰
    time_group = analyze_parser.add_argument_group('æ—¶é—´èŒƒå›´å‚æ•°ï¼ˆå¯é€‰ï¼Œå¤šç§æ–¹å¼ï¼Œäº’æ–¥ï¼‰')
    time_group.add_argument('--years', type=int, default=3, help='åˆ†æè¿‡å»Nå¹´çš„æ•°æ®ï¼ˆé»˜è®¤: 3ï¼‰')
    time_group.add_argument('--months', type=int, help='åˆ†æè¿‡å»Nä¸ªæœˆçš„æ•°æ®ï¼ˆå¦‚ --months 12 è¡¨ç¤ºè¿‡å»12ä¸ªæœˆï¼‰')
    time_group.add_argument('--days', type=int, help='åˆ†æè¿‡å»Nå¤©çš„æ•°æ®ï¼ˆå¦‚ --days 365 è¡¨ç¤ºè¿‡å»365å¤©ï¼‰')
    
    # ç²¾ç¡®æ—¥æœŸèŒƒå›´å‚æ•°ï¼ˆå¯é€‰ï¼Œä¸ä¸Šé¢äº’æ–¥ï¼‰
    date_group = analyze_parser.add_argument_group('ç²¾ç¡®æ—¥æœŸèŒƒå›´å‚æ•°ï¼ˆå¯é€‰ï¼Œä¸æ—¶é—´èŒƒå›´å‚æ•°äº’æ–¥ï¼‰')
    date_group.add_argument('--start-date', help='å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD æˆ– YYYY-MM-DD HH:MM:SSï¼ˆå¦‚ 2023-01-01ï¼‰')
    date_group.add_argument('--end-date', help='ç»“æŸæ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD æˆ– YYYY-MM-DD HH:MM:SSï¼ˆå¦‚ 2024-12-31ï¼‰ã€‚ä¸æŒ‡å®šåˆ™ä½¿ç”¨å½“å‰æ—¶é—´')
    
    analyze_parser.add_argument('--fetch-from-api', action='store_true', help='å¦‚æœæ•°æ®åº“æ•°æ®ä¸å®Œæ•´ï¼Œä» Bybit API è·å–å†å²æ•°æ®')
    analyze_parser.add_argument('--strategy', default='', help='ç­–ç•¥ç±»å‹ç­›é€‰ï¼ˆALL/MACD_3SEG_DIVERGENCE æˆ–ç¡®è®¤é¡¹ç»„åˆå¦‚ ENGULFING+RSI_DIVï¼Œé»˜è®¤: ALLï¼‰')
    analyze_parser.add_argument('--show-all-signals', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰ä¿¡å·çš„è¯¦ç»†ä¿¡æ¯ï¼ˆé»˜è®¤åªæ˜¾ç¤ºå‰10ä¸ªç¤ºä¾‹ï¼‰')
    
    # init-db å‘½ä»¤
    subparsers.add_parser('init-db', help='æ•°æ®åº“è¿ç§»åˆå§‹åŒ–ï¼ˆå¹‚ç­‰ï¼‰')
    
    # init-streams å‘½ä»¤
    subparsers.add_parser('init-streams', help='Redis Streams åˆå§‹åŒ–ï¼ˆå¹‚ç­‰ï¼‰')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if args.command == 'prepare':
        cmd_prepare()
    elif args.command == 'positions':
        cmd_positions(args)
    elif args.command == 'clean':
        cmd_clean(args)
    elif args.command == 'test':
        cmd_test(args)
    elif args.command == 'quick-test':
        cmd_quick_test(args)
    elif args.command == 'orders':
        cmd_orders(args)
    elif args.command == 'diagnose':
        cmd_diagnose(args)
    elif args.command == 'diagnose-signals':
        cmd_diagnose_signals(args)
    elif args.command == 'sync':
        cmd_sync(args)
    elif args.command == 'close-test':
        cmd_close_test(args)
    elif args.command == 'gates-test':
        cmd_gates_test(args)
    elif args.command == 'replay':
        cmd_replay(args)
    elif args.command == 'ratelimit-test':
        cmd_ratelimit_test(args)
    elif args.command == 'ws-test':
        cmd_ws_test(args)
    elif args.command == 'db-check':
        cmd_db_check()
    elif args.command == 'backtest':
        cmd_backtest(args)
    elif args.command == 'replay-report':
        cmd_replay_report(args)
    elif args.command == 'analyze-signals':
        cmd_analyze_signals(args)
    elif args.command == 'init-db':
        cmd_init_db()
    elif args.command == 'init-streams':
        cmd_init_streams()
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()
